{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26ab996",
   "metadata": {},
   "source": [
    "# Understand the kernel with code samples\n",
    "\n",
    "----\n",
    "The kernel is the central component of Semantic Kernel. At its simplest, the kernel is a Dependency Injection container that manages all of the services and plugins necessary to run your AI application. If you provide all of your services and plugins to the kernel, they will then be seamlessly used by the AI as needed. \n",
    "\n",
    "| Components | Description |\n",
    "|------------|-------------|\n",
    "| **1. Services** | These consist of both AI services (e.g., chat completion) and other services (e.g., logging and HTTP clients) that are necessary to run your application. This was modeled after the Service Provider pattern in .NET to support dependency injection across all languages. |\n",
    "| **2. Plugins** | These are components used by your AI services and prompt templates to perform work. For example, AI services can use plugins to retrieve data from a database or call an external API to perform actions. |\n",
    "\n",
    "![kernel](images/the-kernel-is-at-the-center-of-everything.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e456fe",
   "metadata": {},
   "source": [
    "## Hierarchical Architecture Diagram\n",
    "---\n",
    "\n",
    "Architecture of a Retrieval-Augmented Generation (RAG) based chatbot using the latest Semantic Kernel. The diagram highlights how the Agent Framework (for chat interactions) and Process Framework (for workflow orchestration) sit above the core Kernel, leveraging it to perform AI tasks. The Semantic Kernel core orchestrates between user requests and the underlying AI services, memory stores, and plugins. It integrates with external LLM services for generation, uses a vector DB for semantic memory (retrieval of relevant data), and can invoke plugins which may call other external APIs or services as needed.\n",
    "\n",
    "![Hierarchical](images/semantic_kernel_hierarchical_architecture_diagram2.png)\n",
    "\n",
    "***AI Agent (Agent Framework)***: The Agent Framework in Semantic Kernel is an optional layer that helps create conversational AI agents (like chatbots) using the core kernel‚Äôs capabilities‚Äã. It is not a replacement for the kernel but builds on top of it ‚Äì your application still includes the Semantic Kernel library, and the agent uses the kernel‚Äôs functions internally. In a chatbot scenario, the Agent Framework manages the dialogue (turn-taking, system prompts, etc.) while delegating AI tasks to the kernel.\n",
    "\n",
    "***Semantic Kernel (Core)***: The Semantic Kernel core is the heart of the system. It orchestrates calls to AI models, retrieves memories, and executes plugin functions. The kernel provides abstractions to connect to AI services (LLM APIs for text generation, embedding models, etc.) and to various memory stores (for example, vector databases)‚Äã. It also manages context (prompts) and can use Planners to chain or select functions dynamically to fulfill a user request‚Äã. The kernel itself is part of your app‚Äôs runtime, coordinating all other components.\n",
    "\n",
    "***Plugins (Skills/Functions)***: Plugins (also called skills or functions) are units of functionality that the kernel can invoke. They might be defined with natural language prompts (semantic functions) or as native code functions. Plugins can perform calculations, transform data, or call external services/APIs. They are registered with and executed via the kernel, meaning they depend on the kernel to be invoked as part of an AI workflow‚Äã. However, the plugin implementations (e.g. an HTTP call to a web service, a database query) run outside the kernel ‚Äì the kernel just orchestrates their usage. In essence, plugins extend the kernel‚Äôs abilities, and the kernel can automatically chain plugins to accomplish complex tasks for the user‚Äã.\n",
    "\n",
    "***AI Services***: These are external AI model endpoints that the kernel calls through its connectors. For example, the OpenAI or Azure OpenAI service provides the GPT-4 model for text generation, and there are embedding model services for vector generation. The kernel has integrations for many AI services (text completion, chat, image generation, speech recognition, etc.) and it uses them by calling out to the respective APIs‚Äã. These services are not ‚Äúinside‚Äù the kernel ‚Äì instead, the kernel depends on them to provide the intelligence. In the architecture, they appear as external components that the kernel invokes (e.g. sending a prompt to the GPT model and getting a completion).\n",
    "\n",
    "***Semantic Memory (Vector DB)***: The Semantic Kernel includes a memory abstraction that allows storing and retrieving contextual information. Under the hood, this is often backed by a vector database or search index. In a RAG-based chatbot, this is critical: documents or knowledge are embedded into vector representations and stored, so that relevant pieces can be retrieved to ground the AI‚Äôs answers. Semantic Kernel‚Äôs memory can integrate with many vector stores (e.g. Azure Cognitive Search, ChromaDB, Qdrant, Redis, Pinecone, etc.)‚Äã. This means ‚ÄúMemory‚Äù is essentially an AI Search over a vector DB, enabling the bot to find relevant information by semantic similarity. The memory component is used by the kernel but the database itself is external ‚Äì the kernel just sends queries and gets results.\n",
    "\n",
    "***Process Framework (Workflow Orchestration)***: The Process Framework is another optional layer in the latest Semantic Kernel, aimed at long-running or multi-step workflows. It lets developers define structured processes composed of multiple steps, where each step can call kernel functions (AI or non-AI tasks) in an event-driven sequence‚Äã. Like the Agent Framework, the Process Framework builds on the kernel rather than enclosing it. It uses the kernel to execute AI functions at each step of a business workflow. This is especially useful if your chatbot or assistant needs to carry out complex transactions or procedures (for example, an order processing workflow or a support ticket resolution that involves several back-and-forth steps) beyond a single conversational turn. The Process Framework uses technologies like Orleans or Dapr under the hood for reliability and can reuse any existing kernel plugins within those processes‚Äã."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b243d6",
   "metadata": {},
   "source": [
    "## üß™ Step 1. AAAAAA\n",
    "---\n",
    "\n",
    "0. AAAAAA\n",
    "1. BBBB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61247b",
   "metadata": {},
   "source": [
    "## üß™ Step 2. BBBBB\n",
    "---\n",
    "\n",
    "1. CCC\n",
    "2. DDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a73a0",
   "metadata": {},
   "source": [
    "### üöÄ Example of your messages\n",
    "\n",
    "1. What is the history of microsoft?\n",
    "2. get info from https://www.sqlite.org/copyright.html\n",
    "3. what is the weather in Seoul?\n",
    "4. 4.11 + 5.11?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c07ac3",
   "metadata": {},
   "source": [
    "### ‚úÖ sample response\n",
    "\n",
    "1. What is the history of microsoft?\n",
    "\n",
    "![screenshot1](images/screenshot1.png)\n",
    "\n",
    "2. get info from https://www.sqlite.org/copyright.html\n",
    "\n",
    "![screenshot2](images/screenshot2.png)\n",
    "\n",
    "3. what is the weather in Seoul?\n",
    "\n",
    "![screenshot3](images/screenshot3.png)\n",
    "\n",
    "4. 4.11 + 5.11?\n",
    "\n",
    "![screenshot4](images/screenshot4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a2e7aa",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d7df9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
