{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26ab996",
   "metadata": {},
   "source": [
    "# Self-RAG\n",
    "---\n",
    "\n",
    "### What is Self-RAG?\n",
    "\n",
    "Self-RAG reflects on the retrieved documents and generated responses, and includes a self-evaluation process to improve the quality of the generated answers.\n",
    "\n",
    "Original paper says Self-RAG generates special tokens, termed \"reflection tokens,\" to determine if retrieval would enhance the response, allowing for on-demand retrieval integration. \n",
    "But in practice, we can ignore reflection tokens and let LLM decides if each document is relevant or not.\n",
    "\n",
    "Corrective RAG (CRAG) is similar to Self-RAG, but Self-RAG focuses on self-reflection and self-evaluation, while CRAG focuses on refining the entire retrieval process including web search.\n",
    "\n",
    "- Self-RAG: Trains the LLM to be self-sufficient in managing retrieval and generation processes. By generating reflection tokens, the model controls its behavior during inference, deciding when to retrieve information and how to critique and improve its own responses, leading to more accurate and contextually appropriate outputs. \n",
    "- CRAG: Focuses on refining the retrieval process by evaluating and correcting the retrieved documents before they are used in generation. It integrates additional retrievals, such as web searches, when initial retrievals are insufficient, ensuring that the generation is based on the most relevant and accurate information available.\n",
    "\n",
    "**Reference**\n",
    "\n",
    "- [Self-RAG paper](https://arxiv.org/abs/2310.11511)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6458235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.ai.evaluation import GroundednessEvaluator, RelevanceEvaluator, RetrievalEvaluator\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_core.models import ChatCompletionClient, SystemMessage, UserMessage, AssistantMessage\n",
    "from autogen_core import MessageContext, RoutedAgent, SingleThreadedAgentRuntime, TopicId, message_handler, type_subscription\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "load_dotenv(\"../../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05d7dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables\n",
    "azure_ai_search_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "search_credential = AzureKeyCredential(os.getenv(\"AZURE_SEARCH_ADMIN_KEY\", \"\")) if len(os.getenv(\"AZURE_SEARCH_ADMIN_KEY\", \"\")) > 0 else DefaultAzureCredential()\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_KEY\", \"\")) > 0 else None\n",
    "azure_openai_chat_deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_embedding_deployment_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\", \"text-embedding-ada-002\")\n",
    "openai_api_version = os.getenv(\"OPENAI_API_VERSION\", \"2024-06-01\")\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": azure_openai_endpoint,\n",
    "    \"api_key\": azure_openai_key,\n",
    "    \"azure_deployment\": azure_openai_chat_deployment_name,\n",
    "    \"api_version\": openai_api_version,\n",
    "    \"type\": \"azure_openai\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec192a9",
   "metadata": {},
   "source": [
    "## ðŸ§ª Step 1. Test and Construct each module\n",
    "---\n",
    "\n",
    "Before building the entire the graph pipeline, we will test and construct each module separately.\n",
    "\n",
    "- **Retrieval Grader**\n",
    "- **Answer Generator**\n",
    "- **Groundedness Evaluator**\n",
    "- **Relevance Evaluator**\n",
    "- **Question Re-writer**\n",
    "\n",
    "### Construct Retrieval Chain based on PDF\n",
    "- We use the hotels-sample-index, which can be created in minutes and runs on any search service tier. This index is created by a wizard using built-in sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cde195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starlight Suites:Complimentary Airport Shuttle & WiFi. Book Now and save - Spacious All Suite Hotel, Indoor Outdoor Pool, Fitness Center, Florida Green certified, Complimentary Coffee, HDTV:['pool', 'coffee in lobby', 'free wifi']\n",
      "Double Sanctuary Resort:5 star Luxury Hotel - Biggest Rooms in the city. #1 Hotel in the area listed by Traveler magazine. Free WiFi, Flexible check in/out, Fitness Center & espresso in room.:['view', 'pool', 'restaurant', 'bar', 'continental breakfast']\n",
      "Trails End Motel:Only 8 miles from Downtown. On-site bar/restaurant, Free hot breakfast buffet, Free wireless internet, All non-smoking hotel. Only 15 miles from airport.:['bar', 'free wifi', 'restaurant']\n",
      "Gastronomic Landscape Hotel:The Gastronomic Hotel stands out for its culinary excellence under the management of William Dough, who advises on and oversees all of the Hotelâ€™s restaurant services.:['restaurant', 'bar', 'continental breakfast']\n",
      "Head Wind Resort:The best of old town hospitality combined with views of the river and cool breezes off the prairie. Our penthouse suites offer views for miles and the rooftop plaza is open to all guests from sunset to 10 p.m. Enjoy a complimentary continental breakfast in the lobby, and free Wi-Fi throughout the hotel.:['coffee in lobby', 'free wifi', 'view']\n"
     ]
    }
   ],
   "source": [
    "azure_ai_search_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "azure_search_admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\", \"\")\n",
    "search_client = SearchClient(\n",
    "    endpoint=azure_ai_search_endpoint,\n",
    "    index_name=\"hotel_quickstart_vector\",\n",
    "    credential=AzureKeyCredential(azure_search_admin_key),\n",
    "    semantic_configuration_name='my-semantic-config', \n",
    ")\n",
    "\n",
    "# Query is the question being asked. It's sent to the search engine and the LLM.\n",
    "query=\"Can you recommend a few hotels with complimentary breakfast?\"\n",
    "\n",
    "# Search results are created by the search client.\n",
    "# Search results are composed of the top 5 results and the fields selected from the search index.\n",
    "# Search results include the top 5 matches to your query.\n",
    "search_results = search_client.search(\n",
    "    search_text=query,\n",
    "    top=5,\n",
    "    select=\"Description,HotelName,Tags\"\n",
    ")\n",
    "sources_formatted = \"\\n\".join([f'{document[\"HotelName\"]}:{document[\"Description\"]}:{document[\"Tags\"]}' for document in search_results])\n",
    "\n",
    "print(sources_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d39ad",
   "metadata": {},
   "source": [
    "### Define your LLM\n",
    "\n",
    "This hands-on only uses the `gpt-4o-mini`, but you can utilize multiple models in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18d3a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aoai_client = AzureOpenAI(\n",
    "#     azure_endpoint=azure_openai_endpoint,\n",
    "#     api_key=azure_openai_key,\n",
    "#     api_version=openai_api_version,\n",
    "# )\n",
    "\n",
    "# This is not the same object as the one above. This is the client that is used to interact with the Azure OpenAI Chat API.\n",
    "autogen_aoai_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    model = azure_openai_chat_deployment_name,\n",
    "    api_version=openai_api_version,\n",
    "    api_key=azure_openai_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec10e5",
   "metadata": {},
   "source": [
    "### Question-Retrieval Grader\n",
    "\n",
    "Construct a retrieval grader that evaluates the relevance of the retrieved documents to the input question. The retrieval grader should take the input question and the retrieved documents as input and output a relevance score for each document.<br>\n",
    "Note that the retrieval grader should be able to handle **multiple documents** as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c85e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieval': 2.0, 'gpt_retrieval': 2.0, 'retrieval_reason': 'The context contains several relevant hotel options that offer complimentary breakfast, but they are not ranked at the top, and there is irrelevant information included. This leads to a score of 2, indicating partially relevant context with poor ranking.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_eval  = RetrievalEvaluator(model_config)\n",
    "\n",
    "query_response = dict(\n",
    "    query=query,\n",
    "    context=sources_formatted\n",
    ")\n",
    "\n",
    "relevance_score = retrieval_eval(\n",
    "    **query_response\n",
    ")\n",
    "print(relevance_score)\n",
    "relevance_score['retrieval']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b7f87",
   "metadata": {},
   "source": [
    "### Answer Generator\n",
    "\n",
    "Construct a LLM Generation node. This is a Naive RAG chain that generates an answer based on the retrieved documents. \n",
    "\n",
    "We recommend you to use more advanced RAG chain for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2168105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class HotelInfo(BaseModel):\n",
    "    hotel_name: str\n",
    "    description: str\n",
    "\n",
    "class RecommendationList(BaseModel):\n",
    "    recommendation: List[HotelInfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d080f695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hotel_name': 'Trails End Motel', 'description': 'Only 8 miles from Downtown. On-site bar/restaurant, Free hot breakfast buffet, Free wireless internet, All non-smoking hotel.'}\n",
      "{'hotel_name': 'Double Sanctuary Resort', 'description': '5 star Luxury Hotel - Biggest Rooms in the city. #1 Hotel in the area listed by Traveler magazine. Free WiFi, Flexible check in/out, Fitness Center & espresso in room.'}\n",
      "{'hotel_name': 'Head Wind Resort', 'description': 'The best of old town hospitality combined with views of the river and cool breezes off the prairie. Enjoy a complimentary continental breakfast in the lobby, and free Wi-Fi throughout the hotel.'}\n"
     ]
    }
   ],
   "source": [
    "# This prompt provides instructions to the model\n",
    "GROUNDED_PROMPT=\"\"\"\n",
    "You are a friendly assistant that recommends hotels based on activities and amenities.\n",
    "Answer the query using only the context provided below in a friendly and concise bulleted manner.\n",
    "Answer ONLY with the facts listed in the list of context below.\n",
    "If there isn't enough information below, say you don't know.\n",
    "Generate a response that includes the top 3 results.\n",
    "Do not generate answers that don't use the context below.\n",
    "Query: {query}\n",
    "Context:\\n{context}\n",
    "\"\"\"\n",
    "\n",
    "# Send the search results and the query to the LLM to generate a response based on the prompt.\n",
    "response = await autogen_aoai_client.create(\n",
    "        messages = [\n",
    "        UserMessage(content=GROUNDED_PROMPT.format(query=query, context=sources_formatted), source=\"user\"),\n",
    "    ],\n",
    "        extra_create_args={\"response_format\": RecommendationList},\n",
    ")\n",
    "\n",
    "response_content = json.loads(response.content)\n",
    "for recommendation in response_content['recommendation']:\n",
    "    print(recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4050d",
   "metadata": {},
   "source": [
    "### Groundedness Evaluator\n",
    "\n",
    "Construct a `groundedness_grader` node to evaluate the **hallucination** of the generated answer based on the retrieved documents.<br>\n",
    "\n",
    "`yes` means the answer is relevant to the retrieved documents, and `no` means the answer is not relevant to the retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f46b9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 4.0, 'gpt_groundedness': 4.0, 'groundedness_reason': 'The RESPONSE includes two hotels that offer complimentary breakfast but incorrectly lists a third hotel that does not. This makes the response partially correct but not fully accurate or complete, justifying a score of 4.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "groundedness_eval  = GroundednessEvaluator(model_config)\n",
    "\n",
    "query_response = dict(\n",
    "    query=query,\n",
    "    context=sources_formatted,\n",
    "    response=response_content\n",
    ")\n",
    "\n",
    "groundedness_score = groundedness_eval(\n",
    "    **query_response\n",
    ")\n",
    "print(groundedness_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c773d2",
   "metadata": {},
   "source": [
    "### Relevance Evaluator\n",
    "\n",
    "Construct a `relevance_grader` node to evaluate the relevance of the generated answer to the question.<br>\n",
    "`yes` means the answer is relevant to the question, and `no` means the answer is not relevant to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37e10188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': \"The RESPONSE provides a complete and accurate list of hotels that offer complimentary breakfast, fulfilling the QUERY's request effectively.\"}\n"
     ]
    }
   ],
   "source": [
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "\n",
    "query_response = dict(\n",
    "    query=query,\n",
    "    response=response_content\n",
    ")\n",
    "\n",
    "relevance_score = relevance_eval(\n",
    "    **query_response\n",
    ")\n",
    "print(relevance_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05275c",
   "metadata": {},
   "source": [
    "### Question Re-writer\n",
    "\n",
    "Construct a `question_rewriter` node to rewrite the question based on the retrieved documents and the generated answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "806f6d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could you suggest some hotels or accommodations that offer complimentary breakfast?\n"
     ]
    }
   ],
   "source": [
    "query=\"Can you recommend a few factories with complimentary breakfast?\"\n",
    "\n",
    "# This prompt provides instructions to the model\n",
    "REWRITE_PROMPT=\"\"\"\n",
    "You a question re-writer that converts an input question to a better version that is optimized\n",
    "for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\n",
    "Query: {query}\n",
    "\"\"\"\n",
    "\n",
    "# Send the search results and the query to the LLM to generate a response based on the prompt.\n",
    "response = await autogen_aoai_client.create(\n",
    "        messages = [\n",
    "        UserMessage(content=REWRITE_PROMPT.format(query=query), source=\"user\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Here is the response from the chat model.\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d720d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## ðŸ§ª Step 2. Define the Agentic Architecture\n",
    "- Before building the agentic pipeline, we need to design the message, topic, agent and message routing logic. \n",
    "- You should define the terminate condition for the pipeline.\n",
    "\n",
    "### Message, Topic, Agent Definition\n",
    "\n",
    "```markdown\n",
    "```python\n",
    "\n",
    "# Message Definition\n",
    "@dataclass\n",
    "class Message:\n",
    "    query: str = None\n",
    "    context: str = None\n",
    "    response: str = None\n",
    "    source: str = None\n",
    "\n",
    "\n",
    "# Topic Definition\n",
    "user_query_topic_type = \"UserQueryTopic\"\n",
    "rewrite_topic_type = \"RewriteQueryTopic\"\n",
    "generate_topic_type = \"GenerateTopic\"\n",
    "eval_topic_type = \"EvalTopic\"\n",
    "\n",
    "# Agent Definition\n",
    "class RetrievalGraderAgent(RoutedAgent):\n",
    "class RewriteQueryAgent(RoutedAgent):\n",
    "class GenerateAgent(RoutedAgent):\n",
    "class EvalAgent(AssistantAgent):\n",
    "class UserAgent(AssistantAgent):\n",
    "\n",
    "# Message Routing Definition\n",
    "UserAgent -> RetrievalGraderAgent -> RewriteQueryAgent -> RetrievalGraderAgent(revisit) -> GenerateAgent -> EvalAgent -> UserAgent\n",
    "                                  -> GenerateAgent -> EvalAgent -> UserAgent\n",
    "\n",
    "\n",
    "```\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87d1f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Message:\n",
    "    query: str = None\n",
    "    context: str = None\n",
    "    response: str = None\n",
    "    source: str = None\n",
    "    def set_source(self, source: str) -> \"Message\":\n",
    "        self.source = source\n",
    "        return self\n",
    "\n",
    "# Topic Definition\n",
    "user_query_topic_type = \"UserQueryTopic\"\n",
    "rewrite_topic_type = \"RewriteQueryTopic\"\n",
    "generate_topic_type = \"GenerateTopic\"\n",
    "eval_topic_type = \"EvalTopic\"\n",
    "user_topic_type = \"UserAgent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "883dde68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@type_subscription(topic_type=user_query_topic_type)\n",
    "class RAGGraderAgent(RoutedAgent):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            azure_ai_search_endpoint:str, \n",
    "            azure_search_admin_key:str,\n",
    "            index_name: str,\n",
    "            retrieval_evaluator: RetrievalEvaluator,\n",
    "            ) -> None:\n",
    "        \n",
    "        super().__init__(\"RAG Grader Agent\")\n",
    "        self.index_name = index_name\n",
    "        self.azure_ai_search_endpoint = azure_ai_search_endpoint\n",
    "        self.azure_search_admin_key = azure_search_admin_key\n",
    "        self.retrieval_evaluator = retrieval_evaluator\n",
    "\n",
    "    def config_search(self) -> SearchClient:\n",
    "        service_endpoint = self.azure_ai_search_endpoint\n",
    "        key = self.azure_search_admin_key\n",
    "        index_name = self.index_name\n",
    "        credential = AzureKeyCredential(key)\n",
    "        return SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "\n",
    "    async def do_search(self, query: str) -> str:\n",
    "        \"\"\"Search indexed data using Azure Cognitive Search with vector-based queries.\"\"\"\n",
    "        aia_search_client = self.config_search()\n",
    "\n",
    "        fields = \"descriptionVector\" # TODO: Check if this is the correct field name\n",
    "        vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=fields, exhaustive=True)\n",
    " \n",
    "        search_results = aia_search_client.search(  \n",
    "            search_text=query,  \n",
    "            vector_queries= [vector_query],\n",
    "            select=[\"Description,HotelName,Tags\"], #TODO: Check if these are the correct field names\n",
    "            top=3 #TODO: Check if this is the correct number of results\n",
    "        )\n",
    "        answer = \"\\n\".join([f'{document[\"HotelName\"]}:{document[\"Description\"]}:{document[\"Tags\"]}' for document in search_results])  \n",
    "        return answer\n",
    "    \n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        \n",
    "        context_from_ai_search = await self.do_search(message.query)\n",
    "        print(context_from_ai_search)\n",
    "\n",
    "        query_response = dict(\n",
    "            query=query,\n",
    "            context=context_from_ai_search\n",
    "        )\n",
    "\n",
    "        retrieval_score = self.retrieval_evaluator (\n",
    "            **query_response\n",
    "        )\n",
    "\n",
    "        print(f\"retrieval_score: {retrieval_score['retrieval']}\")\n",
    "       \n",
    "        if(retrieval_score[\"retrieval\"] >= 3.0):\n",
    "            await self.publish_message(Message(query=query, context=context_from_ai_search, source=message.source), topic_id=TopicId(type=generate_topic_type, source=message.source))\n",
    "        else:\n",
    "            await self.publish_message(Message(query=query, context=context_from_ai_search, source=message.source), topic_id=TopicId(type=rewrite_topic_type, source=message.source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "452355a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REWRITE_PROMPT=\"\"\"\n",
    "You a question re-writer that converts an input question to a better version that is optimized\n",
    "for vectorstore retrieval. Look at the input and try to rewrite about the underlying semantic intent / meaning.\n",
    "Query: {query}\n",
    "\"\"\"\n",
    "\n",
    "@type_subscription(topic_type=rewrite_topic_type)\n",
    "class QueryRewriteAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"Query Rewrite Agent\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                    You are an helper agent that can rewrite the query.\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        print(message)\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, \n",
    "                        UserMessage(content=REWRITE_PROMPT.format(query=message.query), source=self.id.key),\n",
    "                      ],\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        print(response)\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "        \n",
    "        await self.publish_message(Message(query=response, context=message.context, source=message.source), topic_id=TopicId(type=generate_topic_type, source=message.source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93e9a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt provides instructions to the model\n",
    "GROUNDED_PROMPT=\"\"\"\n",
    "Answer the query using only the context provided below in a friendly and concise bulleted manner.\n",
    "Answer ONLY with the facts listed in the list of context below.\n",
    "If there isn't enough information below, say you don't know.\n",
    "Do not generate answers that don't use the context below.\n",
    "Query: {query}\n",
    "Context:\\n{context}\n",
    "\"\"\"\n",
    "\n",
    "@type_subscription(topic_type=generate_topic_type)\n",
    "class GenerateAgent(RoutedAgent):\n",
    "    def __init__(self, model_client: ChatCompletionClient) -> None:\n",
    "        super().__init__(\"Generate Agent\")\n",
    "        self._system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"\n",
    "                    You are a friendly assistant that recommends hotels based on activities and amenities.\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "        self._model_client = model_client\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "        llm_result = await self._model_client.create(\n",
    "            messages=[self._system_message, \n",
    "                        UserMessage(content=GROUNDED_PROMPT.format(query=message.query, context=message.context), source=self.id.key),\n",
    "                      ],\n",
    "            extra_create_args={\"response_format\": RecommendationList},\n",
    "            cancellation_token=ctx.cancellation_token,\n",
    "        )\n",
    "        response = llm_result.content\n",
    "        assert isinstance(response, str)\n",
    "        print(f\"{'-'*80}\\n{self.id.type}:\\n{response}\")\n",
    "        await self.publish_message(Message(query=message.query, context=message.context, response=response, source=self.id.key), topic_id=TopicId(type=eval_topic_type, source=self.id.key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "942babd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "INCORRECT_ANSWER=\"\"\"\n",
    "Hello, and thank you for bringing this to our attention! I may have provided an inaccurate or misleading response, and I sincerely apologize for the confusion.\n",
    "As an AI, I aim to deliver helpful and accurate information, but sometimes I might misinterpret or generate an incorrect response. Your feedback is invaluable and helps me improve.\n",
    "\n",
    "If you'd like, feel free to share more details or clarify your question, and Iâ€™ll do my best to assist you further. Thank you for your understanding and patience! ðŸ˜Š\n",
    "\"\"\"\n",
    "\n",
    "@type_subscription(topic_type=eval_topic_type)\n",
    "class EvalAgent(RoutedAgent):\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            groundedness_evaluator: GroundednessEvaluator,\n",
    "            relevance_evaluator: RelevanceEvaluator,\n",
    "            ) -> None:\n",
    "        \n",
    "        super().__init__(\"Eval Agent\")\n",
    "        self.groundedness_evaluator = groundedness_evaluator\n",
    "        self.relevance_evaluator = relevance_evaluator\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_message(self, message: Message, ctx: MessageContext) -> None:\n",
    "       \n",
    "        query_response = dict(\n",
    "            query=message.query,\n",
    "            context=message.context,\n",
    "            response=message.response\n",
    "            \n",
    "        )\n",
    "\n",
    "        groundedness_score = self.groundedness_evaluator (\n",
    "            **query_response\n",
    "        )\n",
    "        print(f\"groundness_score: {groundedness_score['groundedness']}\")\n",
    "        if(groundedness_score[\"groundedness\"] < 3.0):\n",
    "            await self.publish_message(AssistantMessage(content=INCORRECT_ANSWER, source=self.id.key), topic_id=TopicId(type=user_topic_type, source=self.id.key))\n",
    "        relevance_score = self.relevance_evaluator (\n",
    "            **query_response\n",
    "        )\n",
    "        print(f\"relevance_score: {relevance_score['relevance']}\")\n",
    "        if(relevance_score[\"relevance\"] < 3.0):\n",
    "            await self.publish_message(AssistantMessage(content=INCORRECT_ANSWER, source=self.id.key), topic_id=TopicId(type=user_topic_type, source=self.id.key))\n",
    "\n",
    "        await self.publish_message(AssistantMessage(content=message.response, source=self.id.key), topic_id=TopicId(type=user_topic_type, source=self.id.key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d39cebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@type_subscription(topic_type=user_topic_type)\n",
    "class UserAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"A user agent that outputs the final copy to the user.\")\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_final_copy(self, message: AssistantMessage, ctx: MessageContext) -> None:\n",
    "        print(f\"\\n{'-'*80}\\n{self.id.type} received final copy:\\n{message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8fce6e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## ðŸ§ª Step 3. Execute the Workflow\n",
    "---\n",
    "\n",
    "### Execute the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c329af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='UserAgent')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "\n",
    "await RAGGraderAgent.register(runtime, type=user_query_topic_type, factory=lambda: RAGGraderAgent(\n",
    "    azure_ai_search_endpoint=azure_ai_search_endpoint,\n",
    "    azure_search_admin_key=azure_search_admin_key,\n",
    "    index_name=\"hotel_quickstart_vector\",\n",
    "    retrieval_evaluator=RetrievalEvaluator(model_config),\n",
    "    ))\n",
    "\n",
    "await QueryRewriteAgent.register(runtime, type=rewrite_topic_type, factory=lambda: QueryRewriteAgent(model_client=autogen_aoai_client))\n",
    "\n",
    "await GenerateAgent.register(runtime, type=generate_topic_type, factory=lambda: GenerateAgent(model_client=autogen_aoai_client))\n",
    "\n",
    "await EvalAgent.register(runtime, type=eval_topic_type, factory=lambda: EvalAgent(\n",
    "    groundedness_evaluator=GroundednessEvaluator(model_config),\n",
    "    relevance_evaluator=RelevanceEvaluator(model_config),\n",
    "    ))\n",
    "\n",
    "\n",
    "await UserAgent.register(runtime, type=user_topic_type, factory=lambda: UserAgent())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32562244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lakefront Captain Inn:Every stay starts with a warm cookie. Amenities like the Counting Sheep sleep experience, our Wake-up glorious breakfast buffet and spacious workout facilities await.:['restaurant', 'laundry service', 'coffee in lobby']\n",
      "Good Business Hotel:1 Mile from the airport. Free WiFi, Outdoor Pool, Complimentary Airport Shuttle, 6 miles from Lake Lanier & 10 miles from downtown. Our business center includes printers, a copy machine, fax, and a work area.:['pool', 'continental breakfast', 'free parking']\n",
      "Starlight Suites:Complimentary Airport Shuttle & WiFi. Book Now and save - Spacious All Suite Hotel, Indoor Outdoor Pool, Fitness Center, Florida Green certified, Complimentary Coffee, HDTV:['pool', 'coffee in lobby', 'free wifi']\n",
      "retrieval_score: 1.0\n",
      "Message(query='Can you recommend a few factories with complimentary breakfast?', context=\"Lakefront Captain Inn:Every stay starts with a warm cookie. Amenities like the Counting Sheep sleep experience, our Wake-up glorious breakfast buffet and spacious workout facilities await.:['restaurant', 'laundry service', 'coffee in lobby']\\nGood Business Hotel:1 Mile from the airport. Free WiFi, Outdoor Pool, Complimentary Airport Shuttle, 6 miles from Lake Lanier & 10 miles from downtown. Our business center includes printers, a copy machine, fax, and a work area.:['pool', 'continental breakfast', 'free parking']\\nStarlight Suites:Complimentary Airport Shuttle & WiFi. Book Now and save - Spacious All Suite Hotel, Indoor Outdoor Pool, Fitness Center, Florida Green certified, Complimentary Coffee, HDTV:['pool', 'coffee in lobby', 'free wifi']\", response=None, source='User')\n",
      "Can you suggest some hotels that offer complimentary breakfast?\n",
      "--------------------------------------------------------------------------------\n",
      "RewriteQueryTopic:\n",
      "Can you suggest some hotels that offer complimentary breakfast?\n",
      "--------------------------------------------------------------------------------\n",
      "GenerateTopic:\n",
      "{\"recommendation\":[{\"hotel_name\":\"Lakefront Captain Inn\",\"description\":\"Offers a Wake-up glorious breakfast buffet.\"},{\"hotel_name\":\"Good Business Hotel\",\"description\":\"Provides a continental breakfast.\"},{\"hotel_name\":\"Starlight Suites\",\"description\":\"Complimentary Coffee available.\"}]}\n",
      "groundness_score: 4.0\n",
      "relevance_score: 3.0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "UserAgent received final copy:\n",
      "{\"recommendation\":[{\"hotel_name\":\"Lakefront Captain Inn\",\"description\":\"Offers a Wake-up glorious breakfast buffet.\"},{\"hotel_name\":\"Good Business Hotel\",\"description\":\"Provides a continental breakfast.\"},{\"hotel_name\":\"Starlight Suites\",\"description\":\"Complimentary Coffee available.\"}]}\n"
     ]
    }
   ],
   "source": [
    "runtime.start()\n",
    "\n",
    "await runtime.publish_message(Message(query=\"Can you recommend a few factory with complimentary breakfast?\", source=\"User\"), topic_id=TopicId(type=user_query_topic_type, source=\"user\"))\n",
    "\n",
    "await runtime.stop_when_idle()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda1a04",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
