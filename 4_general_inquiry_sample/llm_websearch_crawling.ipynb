{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138d2cb2",
   "metadata": {},
   "source": [
    "# LLM with Web Search and Crawl\n",
    "\n",
    "Code to crawl the top n pages of a Google search result and serve them to LLM in order to utilize rich context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5623f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True) \n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "  api_version=\"2024-08-01-preview\"\n",
    ")\n",
    "\n",
    "CHAT_COMPLETIONS_MODEL = os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13ea70",
   "metadata": {},
   "source": [
    "bs4 or scrapy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import scrapy\n",
    "from bs4 import BeautifulSoup\n",
    "import httpx\n",
    "import asyncio\n",
    "from urllib.parse import urljoin\n",
    "from azure.ai.projects.models import MessageRole, BingGroundingTool\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_CSE_ID = os.getenv(\"GOOGLE_CSE_ID\")\n",
    "BING_GROUNDING_PROJECT_CONNECTION_STRING = os.getenv(\"BING_GROUNDING_PROJECT_CONNECTION_STRING\")\n",
    "BING_GROUNDING_AGENT_ID = os.getenv(\"BING_GROUNDING_AGENT_ID\")\n",
    "BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME = os.getenv(\"BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME\")\n",
    "BING_GROUNDING_CONNECTION_NAME = os.getenv(\"BING_GROUNDING_CONNECTION_NAME\")\n",
    "# Web search mode: \"google\" or \"bing\"\n",
    "# it can be changed when users want to use different search engine\n",
    "WEB_SEARCH_MODE = os.getenv(\"WEB_SEARCH_MODE\")\n",
    "\n",
    "def extract_text_and_tables_by_bs4(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # Extract main text\n",
    "    paragraphs = [p.get_text().strip() for p in soup.find_all(\"p\") if p.get_text().strip()]\n",
    "    text = \"\\n\".join(paragraphs)\n",
    "    return text\n",
    "\n",
    "\n",
    "async def extract_text_and_tables_async(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=3, follow_redirects=True) as client:\n",
    "        try:\n",
    "            response = await client.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "        except httpx.HTTPStatusError as e:\n",
    "            # Handle 302 redirect manually if follow_redirects fails\n",
    "            if e.response.status_code == 302 and \"location\" in e.response.headers:\n",
    "                redirect_url = e.response.headers[\"location\"]\n",
    "                if not redirect_url.startswith(\"http\"):\n",
    "                    # handle relative redirects\n",
    "                    redirect_url = urljoin(url, redirect_url)\n",
    "                try:\n",
    "                    response = await client.get(redirect_url, headers=headers)\n",
    "                    response.raise_for_status()\n",
    "                except Exception as e2:\n",
    "                    print(f\"Redirect request failed: {e2}\")\n",
    "                    return \"\"\n",
    "            else:\n",
    "                print(f\"Request failed: {e}\")\n",
    "                return \"\"\n",
    "        except httpx.HTTPError as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "        selector = scrapy.Selector(text=response.text)\n",
    "        paragraphs = [p.strip() for p in selector.css('p::text').getall() if p.strip()]\n",
    "        text = \"\\n\".join(paragraphs)\n",
    "        return text\n",
    "\n",
    "async def add_context_async(top_urls = []):\n",
    "    async def gather_contexts():\n",
    "        tasks = [extract_text_and_tables_async(url) for url in top_urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n",
    "    return await gather_contexts()\n",
    "\n",
    "def google_search(query, num=5):\n",
    "    url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"key\": GOOGLE_API_KEY,\n",
    "        \"cx\": GOOGLE_CSE_ID,\n",
    "        \"num\": num, \n",
    "        \"locale\": \"ko\",  # 한국어로 검색\n",
    "        \"siteSearch\": \"samsung.com\",\n",
    "        \"siteSearchFilter\": \"e\",\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    results = response.json()\n",
    "    return results.get(\"items\", [])\n",
    "\n",
    "def bing_grounding_search(query, num=5, search_type=\"web\"):\n",
    "    try:\n",
    "        creds = DefaultAzureCredential()\n",
    "        \n",
    "        project_client = AIProjectClient.from_connection_string(\n",
    "            credential=creds,\n",
    "            conn_str=BING_GROUNDING_PROJECT_CONNECTION_STRING,\n",
    "        )\n",
    "        \n",
    "        agent_id = BING_GROUNDING_AGENT_ID\n",
    "        \n",
    "        if not agent_id:\n",
    "            print(\"BING_GROUNDING_AGENT_ID is not set. Create new agent...\")\n",
    "            connection_name = BING_GROUNDING_CONNECTION_NAME\n",
    "            \n",
    "            bing_connection = project_client.connections.get(\n",
    "                connection_name=connection_name,\n",
    "            )\n",
    "            conn_id = bing_connection.id\n",
    "            \n",
    "            bing = BingGroundingTool(connection_id=conn_id)\n",
    "            \n",
    "            \n",
    "            agent = project_client.agents.create_agent(\n",
    "                model=BING_GROUNDING_AGENT_MODEL_DEPLOYMENT_NAME,\n",
    "                name=\"temporary-bing-agent\",\n",
    "                instructions=\"You are a helpful assistant that searches the web\",\n",
    "                tools=bing.definitions,\n",
    "                headers={\"x-ms-enable-preview\": \"true\"}\n",
    "            )\n",
    "            agent_id = agent.id\n",
    "            print(f\"New agent created. Agent ID: {agent_id}\")\n",
    "        else:\n",
    "            print(f\"Existing agent ID: {agent_id}\")\n",
    "            try:\n",
    "                agent = project_client.agents.get_agent(agent_id)\n",
    "            except Exception as agent_error:\n",
    "                print(f\"Failed to retrieve agent: {agent_error}\")\n",
    "                return []\n",
    "\n",
    "        thread = project_client.agents.create_thread()\n",
    "        \n",
    "        message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=f\"Search the web for: {query}. Return only the top {num} most relevant results as a list.\",\n",
    "        )\n",
    "\n",
    "        print(f\"Message created, ID: {message.id}\")\n",
    "\n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)\n",
    "        \n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Execution failed: {run.last_error}\")\n",
    "            return []\n",
    "        print(f\"Run completed successfully. Status: {run.status}\")\n",
    "        results = []\n",
    "        response_message = project_client.agents.list_messages(thread_id=thread.id).get_last_message_by_role(\n",
    "            MessageRole.AGENT\n",
    "        )\n",
    "        if response_message.url_citation_annotations:\n",
    "            # Extract content text and annotations\n",
    "            if response_message.content:\n",
    "                for content_item in response_message[\"content\"]:\n",
    "                    if content_item[\"type\"] == \"text\":\n",
    "                        text_content = content_item[\"text\"][\"value\"]\n",
    "                        print(\"Extracted Text Content:\")\n",
    "                        print(text_content)\n",
    "            for annotation in response_message.url_citation_annotations:\n",
    "                if annotation[\"type\"] == \"url_citation\":\n",
    "                    url_citation = annotation[\"url_citation\"]\n",
    "                    url = url_citation[\"url\"]\n",
    "                    title = url_citation[\"title\"]\n",
    "                    # set the results same as google json format\n",
    "                    results.append({\"link\": url, \"title\": title})\n",
    "\n",
    "        if not BING_GROUNDING_AGENT_ID and 'agent' in locals() and hasattr(agent, 'id'):\n",
    "            try:\n",
    "                project_client.agents.delete_agent(agent.id)\n",
    "                \n",
    "            except Exception as delete_error:\n",
    "                print(f\"Error deleting agent: {delete_error}\")\n",
    "\n",
    "        return results if results else []\n",
    "    except Exception as e:\n",
    "        print(f\"Bing Grounding error : {e}\")\n",
    "        return []\n",
    "\n",
    "def web_search(query, num=5, search_type=\"web\"):\n",
    "    \"\"\"환경 변수에 따라 Google Search API 또는 Bing Grounding을 사용하여 검색 수행\"\"\"\n",
    "    \n",
    "    if WEB_SEARCH_MODE == \"bing\":\n",
    "        print(f\"Bing Grounding 검색 사용: {query}\")\n",
    "        try:\n",
    "            return bing_grounding_search(query, num, search_type)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Bing Grounding 검색 중 오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"Google Search API 사용: {query}\")\n",
    "        return google_search(query, num, search_type)\n",
    "\n",
    "       \n",
    "QUERY_REWRITE_PROMPT = \"\"\"\n",
    "            <<지시문>>\n",
    "            너는 구글 검색과 LLM 질의 최적화 전문가야. 사용자가 입력한 질문을 두 가지 목적에 맞게 재작성해.\n",
    "\n",
    "            1. Web Search용 Query Rewrite:\n",
    "            - 사용자의 질문을 실제 검색 엔진 검색창에 입력할 수 있도록, 명확하고 간결한 핵심 키워드 중심의 검색어로 재작성해.\n",
    "            - 불필요한 문장, 맥락 설명은 빼고, 검색에 최적화된 형태로 만들어.\n",
    "            - 핵심 키워드를 반복적으로 사용해 검색의 정확도를 높여.\n",
    "\n",
    "            2. LLM Query용 Rewrite:\n",
    "            - 사용자의 질문을 LLM이 더 잘 이해하고 답변할 수 있도록, 맥락과 의도를 명확히 드러내는 자연스러운 문장으로 재작성해.\n",
    "            - 필요한 경우 추가 설명이나 세부 조건을 포함해서 질문의 목적이 분명히 드러나도록 만들어.\n",
    "            - LLM이 답변에 집중할 수 있도록 핵심 단어를 반복 사용해.\n",
    "\n",
    "            <<예시>>\n",
    "            * 질문: 삼성전자 제품 중 2구 말고 다른 인덕션 추천해줘\n",
    "            * 웹 검색용 재작성: 삼성전자 3구 이상 인덕션 추천\n",
    "            * LLM 답변용 재작성: 삼성전자 인덕션 중 2구 모델이 아닌, 3구 이상 또는 다양한 화구 수를 가진 다른 인덕션 제품을 추천해 주세요. 각 모델의 주요 기능과 장점도 함께 알려주세요.\n",
    "\n",
    "            <<질문>>\n",
    "            {user_query}\n",
    "\n",
    "            <<출력포맷>>\n",
    "            반드시 아래와 같이 json 형식으로 출력해.\n",
    "            {\"web_search\": \"웹 검색용 재작성\", \"llm_query\": \"LLM 답변용 재작성\"}\n",
    "        \"\"\"     \n",
    "  \n",
    "def rewrite_query_for_search_and_llm(query, client: AzureOpenAI):\n",
    "        response = client.chat.completions.create(\n",
    "            model=CHAT_COMPLETIONS_MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": QUERY_REWRITE_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0.8,\n",
    "            max_tokens=300,\n",
    "            response_format= {\"type\": \"json_object\"},\n",
    "        )\n",
    "        \n",
    "        return json.loads(response.choices[0].message.content.strip())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b6f992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Input: 삼성전자 제품 중 2구 말고 다른 인덕션 추천해줘\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rewrite_query_for_search_and_llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33melapsed time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m process_web_search_call(RESULTS_COUNT, \u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mprocess_web_search_call\u001b[39m\u001b[34m(RESULTS_COUNT, input)\u001b[39m\n\u001b[32m     21\u001b[39m start_time = time.time()\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal Input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m query_rewrite = \u001b[43mrewrite_query_for_search_and_llm\u001b[49m(\u001b[38;5;28minput\u001b[39m, client)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWeb Search Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_rewrite[\u001b[33m'\u001b[39m\u001b[33mweb_search\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLLM Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_rewrite[\u001b[33m'\u001b[39m\u001b[33mllm_query\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'rewrite_query_for_search_and_llm' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "RESULTS_COUNT = 3\n",
    "\n",
    "inputs = [\n",
    "    \"삼성전자 제품 중 2구 말고 다른 인덕션 추천해줘\",\n",
    "    \"부모님에게 선물하고 싶은데 삼성전자 TV 추천해줘\",\n",
    "    \"삼성전자 25년 제품이 작년 대비 좋아진것은\",\n",
    "    \"삼성전자 JBL과 하만카돈 차이점이 뭐야\",\n",
    "    \"갤럭시 버즈 이어버드 한쪽을 새로 구매했는데 페어링 어떻게 하나요\",\n",
    "    \"삼성전자 S25 무게가 S24와 비교 했을때 얼마나 차이나\"\n",
    "]\n",
    "\n",
    "#TODO 날씨나 뉴스, 기타 다른 특정정보는 Function Call\n",
    "# inputs = [\"날씨, 뉴스\"] ##\n",
    "\n",
    "async def process_web_search_call(RESULTS_COUNT, input):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Original Input: {input}\")\n",
    "    \n",
    "    query_rewrite = rewrite_query_for_search_and_llm(input, client)\n",
    "    print(f\"Web Search Query: {query_rewrite['web_search']}\")\n",
    "    print(f\"LLM Query: {query_rewrite['llm_query']}\")\n",
    "\n",
    "    results = web_search(query_rewrite['web_search'], RESULTS_COUNT)\n",
    "    if results and isinstance(results, list) and len(results) > 0:\n",
    "        print(f\"Web Search Results: {len(results)}\")\n",
    "        top_urls = [results[i][\"link\"] for i in range(len(results))]\n",
    "        contexts = await add_context_async(top_urls)\n",
    "    else:\n",
    "        print(\"No results found or invalid response from web_search.\")\n",
    "        contexts = []\n",
    "\n",
    "    # for i, context in enumerate(contexts):\n",
    "    #     print(f\"Context {i+1}: {context}...\")  # Print first 1000 chars of each context\n",
    "    #     print(\"\\n--- End of Context ---\\n\")\n",
    "\n",
    "    now = datetime.now()\n",
    "    year = now.year\n",
    "    month = now.month\n",
    "    day = now.day\n",
    "\n",
    "    system_prompt = \"너는 삼성전자 제품 관련 정보를 제공하는 챗봇이야. 답변은 마크다운으로 이모지를 1~2개 포함해서 작성해줘.\"\n",
    "    user_prompt = f\"\"\"\n",
    "        너는 아래 제공하는 웹검색색에서 검색한 컨텍스트를 바탕으로 질문에 대한 답변을 제공해야 해. 컨텍스트를 최대한 활용하여 풍부하게 답변을 해야해. \n",
    "        현재는 {year}년 {month}월 {day}일이므로 최신의 데이터를 기반으로 답변을 해줘.\n",
    "        구글에서 제공한 컨텍스트: {contexts}\n",
    "        질문: {query_rewrite['llm_query']}\n",
    "        \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=CHAT_COMPLETIONS_MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                 {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        top_p=0.9,\n",
    "        max_tokens=1500\n",
    "    )\n",
    "\n",
    "    display(Markdown(response.choices[0].message.content))\n",
    "    end_time = time.time()\n",
    "    print(f\"elapsed time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "for input in inputs:\n",
    "    await process_web_search_call(RESULTS_COUNT, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35adba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc1148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb84306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_agentlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
