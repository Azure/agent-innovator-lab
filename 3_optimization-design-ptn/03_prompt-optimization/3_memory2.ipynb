{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d5666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initialized AzuureOpenAI client ===\n",
      "AZURE_OPENAI_ENDPOINT=https://aihubeastus-aiservices.openai.azure.com/\n",
      "AZURE_OPENAI_API_VERSION=2025-01-01-preview\n",
      "AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "aoai_api_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "aoai_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "\n",
    "if not aoai_api_version:\n",
    "    aoai_api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "if not aoai_deployment_name:\n",
    "    aoai_deployment_name = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "\n",
    "try:\n",
    "    print(\"=== Initialized AzuureOpenAI client ===\")\n",
    "    print(f\"AZURE_OPENAI_ENDPOINT={aoai_api_endpoint}\")\n",
    "    print(f\"AZURE_OPENAI_API_VERSION={aoai_api_version}\")\n",
    "    print(f\"AZURE_OPENAI_DEPLOYMENT_NAME={aoai_deployment_name}\")\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25957ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daekeun/.pyenv/versions/3.12.2/envs/py312-dev/lib/python3.12/site-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from azure_genai_utils.rag.pdf import PDFRetrievalChain\n",
    "\n",
    "pdf_path = \"./AutoGen-paper.pdf\"\n",
    "\n",
    "pdf = PDFRetrievalChain(\n",
    "    source_uri=[pdf_path],\n",
    "    loader_type=\"PDFPlumber\",\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    embedding_name=\"text-embedding-3-large\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    ").create_chain()\n",
    "\n",
    "pdf_retriever = pdf.retriever\n",
    "pdf_chain = pdf.chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12935d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.prompts import load_prompt\n",
    "# from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "\n",
    "# def format_docs(docs):\n",
    "#     return \"\\n\\n\".join(\n",
    "#         [\n",
    "#             f'<document><content>{doc.page_content}</content><source>{doc.metadata[\"source\"]}</source><page>{doc.metadata[\"page\"]+1}</page></document>'\n",
    "#             for doc in docs\n",
    "#         ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1641f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Literal, Optional\n",
    "\n",
    "import tiktoken\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b9c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    chunk_size=1000,\n",
    ")\n",
    "recall_vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644bcb72",
   "metadata": {},
   "source": [
    "### Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65772621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def get_user_id(config: RunnableConfig) -> str:\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    if user_id is None:\n",
    "        raise ValueError(\"User ID needs to be provided to save a memory.\")\n",
    "\n",
    "    return user_id\n",
    "\n",
    "\n",
    "@tool\n",
    "def save_recall_memory(memory: str, config: RunnableConfig) -> str:\n",
    "    \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "    document = Document(\n",
    "        page_content=memory, id=str(uuid.uuid4()), metadata={\"user_id\": user_id}\n",
    "    )\n",
    "    recall_vector_store.add_documents([document])\n",
    "    return memory\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_recall_memories(query: str, config: RunnableConfig) -> List[str]:\n",
    "    \"\"\"Search for relevant memories.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "\n",
    "    def _filter_function(doc: Document) -> bool:\n",
    "        return doc.metadata.get(\"user_id\") == user_id\n",
    "\n",
    "    documents = recall_vector_store.similarity_search(\n",
    "        query, k=3, filter=_filter_function\n",
    "    )\n",
    "    return [document.page_content for document in documents]\n",
    "\n",
    "\n",
    "@tool\n",
    "def pdf_retrieve(query: str, config: RunnableConfig):\n",
    "    \"\"\"Retrieve information regarding AutoGen paper. If the query asks for details about AutoGen, use this tool.\"\"\"\n",
    "    print(\"\\n==== [RETRIEVE] ====\\n\")\n",
    "    # msg = state[\"messages\"][-1][\"user\"]\n",
    "    # convo_str = get_buffer_string(state[\"messages\"])\n",
    "    documents = pdf_retriever.invoke(query)\n",
    "    return [document.page_content for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b760cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure_genai_utils.tools import BingSearch\n",
    "\n",
    "WEB_SEARCH_FORMAT_OUTPUT = False\n",
    "\n",
    "web_search_tool = BingSearch(\n",
    "    max_results=1,\n",
    "    locale=\"en-US\",\n",
    "    include_news=False,\n",
    "    include_entity=False,\n",
    "    format_output=WEB_SEARCH_FORMAT_OUTPUT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d20006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search = TavilySearchResults(max_results=1)\n",
    "tools = [save_recall_memory, search_recall_memories, pdf_retrieve, web_search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e99967ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    # add memories that will be retrieved based on the conversation context\n",
    "    recall_memories: Annotated[List[str], \"List of recall memories\"]\n",
    "    # documents: Annotated[List[str], \"List of documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47dcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prpmpt = \"\"\"\n",
    "You are a helpful assistant with advanced long-term memory capabilities. \n",
    "Powered by a stateless LLM, you must rely on external memory to store information between conversations. \n",
    "Utilize the available memory tools to store and retrieve important details that will help you better attend to the user's needs and understand their context.\n",
    "\n",
    "## Memory Usage Guidelines:\n",
    "1. Actively use memory tools (save_core_memory, save_recall_memory) to build a comprehensive understanding of the user.\n",
    "2. Make informed suppositions and extrapolations based on stored memories.\n",
    "3. Regularly reflect on past interactions to identify patterns and preferences.\n",
    "4. Update your mental model of the user with each new piece of information.\n",
    "5. Cross-reference new information with existing memories for consistency.\n",
    "6. Prioritize storing emotional context and personal values alongside facts.\n",
    "7. Use memory to anticipate needs and tailor responses to the user's style.\n",
    "8. Recognize and acknowledge changes in the user's situation or perspectives over time.\n",
    "9. Leverage memories to provide personalized examples and analogies.\n",
    "10. Recall past challenges or successes to inform current problem-solving.\n",
    "\n",
    "## Constraint\n",
    "1. Review the provided context thoroughly and extract key details related to the question.\n",
    "2. Craft a precise answer based on the relevant information.\n",
    "3. Keep the answer concise but logical/natural/in-depth.\n",
    "4. If the retrieved context does not contain relevant information or no context is available, respond with: 'I can't find the answer to that question in the context.'\n",
    "\n",
    "## Recall Memories\n",
    "Recall memories are contextually retrieved based on the current conversation:\n",
    "{recall_memories}\n",
    "\n",
    "## Instructions\n",
    "Engage with the user naturally, as a trusted colleague or friend. There's no need to explicitly mention your memory capabilities. \n",
    "Instead, seamlessly incorporate your understanding of the user into your responses. \n",
    "Be attentive to subtle cues and underlying emotions. Adapt your communication style to match the user's preferences and current emotional state. \n",
    "Use tools to persist information you want to retain in the next conversation. \n",
    "If you do call tools, all text preceding the tool call is an internal message. \n",
    "Respond AFTER calling the tool, once you have confirmation that the tool completed successfully.\n",
    "\"\"\"\n",
    "\n",
    "# Define the prompt template for the agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prpmpt),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f88e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 예쁘게 출력\n",
    "# print(prompt.pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9b2001",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(model_name=aoai_deployment_name)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "# def retrieve(state: State) -> State:\n",
    "#     \"\"\"\n",
    "#     Retrieve documents based on the user question.\n",
    "#     \"\"\"\n",
    "#     print(\"\\n==== [RETRIEVE] ====\\n\")\n",
    "#     # msg = state[\"messages\"][-1][\"user\"]\n",
    "#     convo_str = get_buffer_string(state[\"messages\"])\n",
    "#     documents = pdf_retriever.invoke(convo_str)\n",
    "#     return {\"documents\": documents}\n",
    "\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    # add memories that will be retrieved based on the conversation context\n",
    "    recall_memories: Annotated[List[str], \"List of recall memories\"]\n",
    "\n",
    "\n",
    "def agent(state: State) -> State:\n",
    "    \"\"\"Process the current state and generate a response using the LLM.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "\n",
    "    Returns:\n",
    "        schemas.State: The updated state with the agent's response.\n",
    "    \"\"\"\n",
    "    bound = prompt | model_with_tools\n",
    "    recall_str = (\n",
    "        \"<recall_memory>\\n\" + \"\\n\".join(state[\"recall_memories\"]) + \"\\n</recall_memory>\"\n",
    "    )\n",
    "    prediction = bound.invoke(\n",
    "        {\n",
    "            \"messages\": state[\"messages\"],\n",
    "            # \"context\": format_docs(state[\"documents\"]),\n",
    "            \"recall_memories\": recall_str,\n",
    "        }\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": [prediction],\n",
    "    }\n",
    "\n",
    "\n",
    "def load_memories(state: State, config: RunnableConfig) -> State:\n",
    "    \"\"\"Load memories for the current conversation.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "        config (RunnableConfig): The runtime configuration for the agent.\n",
    "\n",
    "    Returns:\n",
    "        State: The updated state with loaded memories.\n",
    "    \"\"\"\n",
    "    convo_str = get_buffer_string(state[\"messages\"])\n",
    "    convo_str = tokenizer.decode(tokenizer.encode(convo_str)[:2048])\n",
    "    recall_memories = search_recall_memories.invoke(convo_str, config)\n",
    "    return {\n",
    "        \"recall_memories\": recall_memories,\n",
    "    }\n",
    "\n",
    "\n",
    "def route_tools(state: State):\n",
    "    \"\"\"Determine whether to use tools or end the conversation based on the last message.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "\n",
    "    Returns:\n",
    "        Literal[\"tools\", \"__end__\"]: The next step in the graph.\n",
    "    \"\"\"\n",
    "    msg = state[\"messages\"][-1]\n",
    "    if msg.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b20e1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph and add nodes\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(load_memories)\n",
    "builder.add_node(agent)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add edges to the graph\n",
    "builder.add_edge(START, \"load_memories\")\n",
    "builder.add_edge(\"load_memories\", \"agent\")\n",
    "builder.add_conditional_edges(\"agent\", route_tools, [\"tools\", END])\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e850925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6697192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_stream_chunk(chunk):\n",
    "    for node, updates in chunk.items():\n",
    "        print(f\"Update from node: {node}\")\n",
    "        if \"messages\" in updates:\n",
    "            updates[\"messages\"][-1].pretty_print()\n",
    "        else:\n",
    "            print(updates)\n",
    "\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6f0563c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': []}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_RnPKSwbwnR33G3BikwwUNFVH)\n",
      " Call ID: call_RnPKSwbwnR33G3BikwwUNFVH\n",
      "  Args:\n",
      "    memory: Daekeun is passionate about Machine Learning and enjoys learning new concepts related to AI and ML.\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "Daekeun is passionate about Machine Learning and enjoys learning new concepts related to AI and ML.\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! If you want to delve into any specific AI or Machine Learning topics, let me know!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: we're specifying `user_id` to save memories for a given user\n",
    "config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}}\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Daekeun is a Machine Learning geek. He loves to learn AIML new things.\")]},\n",
    "    config=config,\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19fd1c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': ['Daekeun is passionate about Machine Learning and enjoys learning new concepts related to AI and ML.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_lGAVrh9UHJ7TckqOngfBOHjY)\n",
      " Call ID: call_lGAVrh9UHJ7TckqOngfBOHjY\n",
      "  Args:\n",
      "    memory: Daekeun provides AI and Machine Learning technology support at Microsoft.\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "Daekeun provides AI and Machine Learning technology support at Microsoft.\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's impressive! Let me know if there's any way I can assist with your work or learning endeavors in AIML.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Daekeun provides AIML technology support at Microsoft.\")]},\n",
    "    config=config,\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "776b9339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': ['Daekeun provides AI and Machine Learning technology support at Microsoft.', 'Daekeun is passionate about Machine Learning and enjoys learning new concepts related to AI and ML.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  pdf_retrieve (call_xtbWZ0mupRSllAjkj7RTWLrR)\n",
      " Call ID: call_xtbWZ0mupRSllAjkj7RTWLrR\n",
      "  Args:\n",
      "    query: AutoGen\n",
      "\n",
      "\n",
      "\n",
      "==== [RETRIEVE] ====\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: pdf_retrieve\n",
      "\n",
      "[\"tasks. AutoGen agents are customizable, conversable, and can operate in vari-\\nous modes that employ combinations of LLMs, human inputs, and tools. Using\\nAutoGen, developers can also flexibly define agent interaction behaviors. Both\\nnaturallanguageandcomputercodecanbeusedtoprogramflexibleconversation\\npatterns for different applications. AutoGen serves as a generic framework for\\nbuilding diverse applications of various complexities and LLM capacities. Em-\", \"message. AutoGen also introduces and by default adopts an agent auto-reply mechanism to\\nrealizeconversation-drivencontrol: Onceanagentreceivesamessagefromanotheragent,itau-\\ntomaticallyinvokesgenerate replyandsendsthereplybacktothesenderunlessatermination\\nconditionissatisfied. AutoGenprovidesbuilt-inreplyfunctionsbasedonLLMinference,code\\norfunctionexecution,orhumaninput.Onecanalsoregistercustomreplyfunctionstocustomize\", \"ingaspecializeddecision-makingagentforeverynewenvironment.\\nWorkflow. We demonstrate how to use AutoGen to build a working system for handling such\\nscenarios with the MiniWoB++ benchmark (Shi et al., 2017). MiniWoB++ comprises browser in-\\nteraction tasks that involve utilizing mouse and keyboard actions to interact with browsers. The\\nultimateobjectiveofeachtaskistocompletethetasksdescribedconciselyinnaturallanguage,such\", \"‘static’pattern, agenttopologyremainsunchangedregardlessofdifferentinputs. AutoGenallows\\nflexible conversation patterns, including both static and dynamic patterns that can be customized\\nbased on different application needs. execution-capable: whether the system can execute LLM-\\ngenerated code; human involvement: whether (and how) the system allows human participation\\nduringtheexecutionprocessofthesystem. AutoGenallowsflexiblehumaninvolvementinmulti-\", \"patterns. In addition to static conversation with predefined flow, AutoGen also supports dynamic\\nconversation flows with multiple agents. AutoGen provides two general ways to achieve this: 1)\\nCustomized generate reply function: within the customized generate reply function, one\\nagentcanholdthecurrentconversationwhileinvokingconversationswithotheragentsdepending\\nonthecontentofthecurrentmessageandcontext. 2)Functioncalls: Inthisapproach,LLMdecides\", \"limittheframework’sscopeofapplicabilityandgenerality.\\nWhile there is contemporaneous exploration of multi-agent approaches,3 we present AutoGen, a\\ngeneralizedmulti-agentconversationframework(Figure1),basedonthefollowingnewconcepts.\\n1 Customizableandconversableagents. AutoGenusesagenericdesignofagentsthatcanlever-\\nage LLMs, human inputs, tools, or a combination of them. The result is that developers can\", \"figureillustratesthebuilt-inagentsprovidedbyAutoGen,whichhaveunifiedconversationinterfaces\\nand can be customized. The middle sub-figure shows an example of using AutoGen to develop\\na two-agent system with a custom reply function. The bottom sub-figure illustrates the resulting\\nautomatedagentchatfromthetwo-agentsystemduringprogramexecution.\\nByallowingcustomagentsthatcanconversewitheachother,conversableagentsinAutoGenserve\", \"AutoGenagentsareconversable,customizable,andcanbebasedonLLMs,tools,humans,oreven\\na combination of them. (Top-middle) Agents can converse to solve tasks. (Right) They can form\\na chat, potentially with humans in the loop. (Bottom-middle) The framework supports flexible\\nconversationpatterns.\\nAbstract\\nAutoGen2 isanopen-sourceframeworkthatallowsdeveloperstobuildLLMap-\\nplications via multiple agents that can converse with each other to accomplish\", \"agent systems that can easily fulfill various practical requirements, such as reusing, customizing,\\nandextendingexistingagents,aswellasprogrammingconversationsbetweenthem.\\nOurexperiments,asdetailedinSection3,demonstratethatthisapproachoffersnumerousbenefits.\\nTheadoptionofAutoGenhasresultedinimprovedperformance(overstate-of-the-artapproaches),\\nreduced development code, and decreased manual burden for existing applications. It offers flex-\", \"gramminglanguagestobuildapplicationswithawiderangeofconversationpatternsandagent\\nbehaviors. AutoGenprovidesready-to-useimplementationsandalsoallowseasyextensionand\\nexperimentationforbothsteps. (Section2.2)\\n3WerefertoAppendixAforadetaileddiscussion.\\n2\"]\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "AutoGen is an open-source framework designed to develop applications using multiple agents powered by large language models (LLMs). It supports flexible and customizable agent conversations, allowing them to leverage tools, human inputs, or combinations of these. The framework emphasizes the development of diverse applications through customizable interaction behaviors, flexible conversation patterns, and adaptable agent capabilities.\n",
      "\n",
      "Key aspects include:\n",
      "- **Conversable, Customizable Agents:** These agents can use LLMs, tools, and human inputs to address a variety of tasks.\n",
      "- **Dynamic Conversation Flows:** AutoGen supports both static and dynamic patterns, enabling complex multi-agent interactions.\n",
      "- **Built-in Features:** AutoGen provides tools like automated reply mechanisms and execution capabilities (LLM-generated code or human involvement).\n",
      "- **Ease of Development:** Developers enjoy reduced code burden, customizable workflows, and improved operational efficiency for applications.\n",
      "\n",
      "Let me know if you'd like a deeper dive into specific features or applications!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Daekeun wants to know AutoGen\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c034f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': ['Daekeun provides AI and Machine Learning technology support at Microsoft.', 'Daekeun is passionate about Machine Learning and enjoys learning new concepts related to AI and ML.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "AutoGen’s main features include:\n",
      "\n",
      "1. **Customizable and Conversable Agents**: \n",
      "   - AutoGen agents are designed to be adaptable, capable of leveraging large language models (LLMs), human inputs, tool integrations, or a combination of these.\n",
      "\n",
      "2. **Dynamic and Flexible Conversation Patterns**: \n",
      "   - AutoGen supports both static and dynamic conversation flows, allowing agents to converse and adjust based on different application needs.\n",
      "\n",
      "3. **Agent Interaction Behavior**:\n",
      "   - Developers can define flexible and programmable conversation workflows, including customized reply functions and behavioral patterns.\n",
      "\n",
      "4. **Tool Integration and Execution**:\n",
      "   - AutoGen enables automatic execution capabilities for LLM-generated code and supports human involvement during the process.\n",
      "\n",
      "5. **Multi-Agent Collaboration**:\n",
      "   - Multiple agents can collaborate, exchange messages, and engage in system-level interactions to solve tasks efficiently.\n",
      "\n",
      "6. **Efficient Application Development**:\n",
      "   - Reduces development code burden and manual effort while allowing experimentation, extension, and reuse of existing agent frameworks.\n",
      "\n",
      "7. **Open-Source Flexibility**:\n",
      "   - Includes built-in tools and APIs for developing AI applications, making it accessible for use and modification.\n",
      "\n",
      "AutoGen facilitates the creation of robust and scalable applications where agents can work independently or collaborate seamlessly. Let me know if you want to explore its implementation techniques or specific use cases!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"What is AutoGen's main featrues?\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ddad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Daekeun wants to study AutoGen in 4 weeks. How can he does?\")\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50924fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45f92e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': ['Daekeun provides AI and Machine Learning technology support at Microsoft.', 'Daekeun is passionate about Machine Learning and enjoys learning new concepts related to AI and ML.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  bing_search_results (call_ZylvsVW2yFx8TeL13HUNBUrz)\n",
      " Call ID: call_ZylvsVW2yFx8TeL13HUNBUrz\n",
      "  Args:\n",
      "    query: Microsoft learning material AutoGen study\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: bing_search_results\n",
      "\n",
      "[{\"kind\": \"web\", \"title\": \"AutoGen: Publications - Microsoft Research\", \"snippet\": \"<b>AutoGen</b>: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang (Eric) Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Ahmed Awadallah, Ryen W. White, Doug Burger, Chi Wang COLM 2024 | August 2024 . Best Paper, LLM Agents Workshop ICLR&#39;24 Publication Video Video Video\", \"content\": \"Open-Source Framework for Agentic AI aka.ms/autogen(opens in new tab) autogen@microsoft.com Gagan Bansal,Jennifer Wortman Vaughan,Saleema Amershi,Eric Horvitz,Adam Fourney,Hussein Mozannar,Victor Dibia, Daniel S. Weld MSR-TR-2024-53 | December 2024 Published by Microsoft Publication Victor Dibia,Jingya Chen,Gagan Bansal,Suff Syed,Adam Fourney,Erkang (Eric) Zhu, Chi Wang,Saleema Amershi August 2024 Preprint PDFPublicationVideoVideo Qingyun Wu,Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,Erkang (Eric) Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang,Ahmed Awadallah,Ryen W. White,Doug Burger, Chi Wang COLM 2024| August 2024 Best Paper, LLM Agents Workshop ICLR'24 PublicationVideoVideoVideo Ching-An Cheng,Andrey Kolobov, Dipendra Misra, Allen Nie, Adith Swaminathan December 2023 December 2023 PublicationPreprintGithubProject Chi Wang,  Susan Xueqing Liu,Ahmed Awadallah March 2023 PublicationGithubGithubProject Gagan Bansal,Jennifer Wortman Vaughan,Saleema Amershi,Eric Horvitz,Adam Fourney,Hussein Mozannar,Victor Dibia, Daniel S. Weld MSR-TR-2024-53 | December 2024 Published by Microsoft Publication Victor Dibia,Jingya Chen,Gagan Bansal,Suff Syed,Adam Fourney,Erkang (Eric) Zhu, Chi Wang,Saleema Amershi August 2024 Preprint PDFPublicationVideoVideo Qingyun Wu,Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,Erkang (Eric) Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang,Ahmed Awadallah,Ryen W. White,Doug Burger, Chi Wang COLM 2024| August 2024 Best Paper, LLM Agents Workshop ICLR'24 PublicationVideoVideoVideo Ching-An Cheng,Andrey Kolobov, Dipendra Misra, Allen Nie, Adith Swaminathan December 2023 December 2023 PublicationPreprintGithubProject Chi Wang,  Susan Xueqing Liu,Ahmed Awadallah March 2023 PublicationGithubGithubProject Gagan Bansal,Jennifer Wortman Vaughan,Saleema Amershi,Eric Horvitz,Adam Fourney,Hussein Mozannar,Victor Dibia, Daniel S. Weld MSR-TR-2024-53 | December 2024 Published by Microsoft Publication Victor Dibia,Jingya Chen,Gagan Bansal,Suff Syed,Adam Fourney,Erkang (Eric) Zhu, Chi Wang,Saleema Amershi August 2024 Preprint PDFPublicationVideoVideo Qingyun Wu,Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,Erkang (Eric) Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang,Ahmed Awadallah,Ryen W. White,Doug Burger, Chi Wang COLM 2024| August 2024 Best Paper, LLM Agents Workshop ICLR'24 PublicationVideoVideoVideo Gagan Bansal,Jennifer Wortman Vaughan,Saleema Amershi,Eric Horvitz,Adam Fourney,Hussein Mozannar,Victor Dibia, Daniel S. Weld MSR-TR-2024-53 | December 2024 Published by Microsoft Publication Victor Dibia,Jingya Chen,Gagan Bansal,Suff Syed,Adam Fourney,Erkang (Eric) Zhu, Chi Wang,Saleema Amershi August 2024 Preprint PDFPublicationVideoVideo Ching-An Cheng,Andrey Kolobov, Dipendra Misra, Allen Nie, Adith Swaminathan December 2023 December 2023 PublicationPreprintGithubProject Qingyun Wu,Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li,Erkang (Eric) Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang,Ahmed Awadallah,Ryen W. White,Doug Burger, Chi Wang COLM 2024| August 2024 Best Paper, LLM Agents Workshop ICLR'24 PublicationVideoVideoVideo Chi Wang,  Susan Xueqing Liu,Ahmed Awadallah March 2023 PublicationGithubGithubProject  Follow us: Share this page:\", \"url\": \"https://www.microsoft.com/en-us/research/project/autogen/publications/\", \"thumbnail_url\": null, \"source\": \"Microsoft\"}]\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You can explore AutoGen resources through Microsoft's research page, which has publications and learning materials about AutoGen [here](https://www.microsoft.com/en-us/research/project/autogen/publications/). This should be a great starting point to understand its functionalities, features, and applications. Let me know if you'd like further assistance!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Daekeun wants to study AutoGen in 2 weeks. Please recommend Microsoft's website or appropriate learning material.\")\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8bf9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a7ce1d",
   "metadata": {},
   "source": [
    "Now we can use the saved information about our user on a different thread. Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8908707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': []}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_msnnVuceYB8ysbCUtZsoC5mE)\n",
      " Call ID: call_msnnVuceYB8ysbCUtZsoC5mE\n",
      "  Args:\n",
      "    memory: Hyo is a big fan of Microsoft.\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "Hyo is a big fan of Microsoft.\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's awesome! If Hyo is curious about anything related to Microsoft—like its products, services, or innovations—I'd be happy to help or share some insights.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"2\", \"thread_id\": \"1\"}}\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Hyo is a big fan of Microsoft\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d44ab64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': ['Hyo is a big fan of Microsoft.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_XrTkFbnbEkcPj6JFGBs4x5CJ)\n",
      " Call ID: call_XrTkFbnbEkcPj6JFGBs4x5CJ\n",
      "  Args:\n",
      "    memory: Hyo is interested in AutoGen and Semantic Kernel.\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "Hyo is interested in AutoGen and Semantic Kernel.\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great! If Hyo needs resources, explanations, or guidance on AutoGen or Semantic Kernel, I can provide helpful information or recommendations. Just let me know!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"2\", \"thread_id\": \"1\"}}\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Hyo is interested in AutoGen and Semantic Kernel\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d26af86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': ['Hyo is interested in AutoGen and Semantic Kernel.', 'Hyo is a big fan of Microsoft.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "For AutoGen, you can find detailed learning materials, publications, and insights on Microsoft's official page [here](https://www.microsoft.com/en-us/research/project/autogen/publications/).\n",
      "\n",
      "For Semantic Kernel, its primary learning resources are on its [GitHub repository](https://github.com/microsoft/semantic-kernel), where you'll find documentation, examples, and implementation guidelines to study and experiment with the framework.\n",
      "\n",
      "Let me know if you'd like further assistance navigating or understanding these materials!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"2\", \"thread_id\": \"1\"}}\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Where is learning materials?\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618f9d1f",
   "metadata": {},
   "source": [
    "Notice how the agent is loading the most relevant memories before answering, and in our case suggests the dinner recommendations based on both the food preferences as well as location.\n",
    "\n",
    "Finally, let's use the search tool together with the rest of the conversation context and memory to find location of a pizzeria:\n",
    "\n",
    "에이전트가 답변하기 전에 가장 관련성 높은 기억을 불러오는 방식에 주목하세요. 이 경우에는 음식 선호도와 위치를 모두 고려하여 저녁 식사 추천을 제안합니다.\n",
    "\n",
    "마지막으로, 검색 도구를 나머지 대화 맥락 및 기억과 함께 사용하여 피자 가게의 위치를 ​​찾아 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fa1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"what's the address for joe's in greenwich village?\")]},\n",
    "    config=config,\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5c10f",
   "metadata": {},
   "source": [
    "### Adding structured memories\n",
    "\n",
    "지금까지 메모리를 문자열로 표현했습니다(예: \"John은 피자를 좋아해\"). 이는 메모리를 벡터 저장소에 저장할 때 자연스러운 표현입니다. 그래프 데이터베이스와 같은 다른 지속성 백엔드를 사용하는 것이 유용하다면, 애플리케이션을 업데이트하여 추가적인 구조를 가진 메모리를 생성할 수 있습니다.\n",
    "\n",
    "아래에서는 save_recall_memory 도구를 업데이트하여 지식 그래프에 저장하기에 적합한 \"지식 트리플\", 즉 주어, 술어, 목적어를 가진 3-튜플 목록을 받습니다. 그러면 모델이 도구 호출의 일부로 이러한 표현을 생성합니다.\n",
    "\n",
    "간단성을 위해 이전과 동일한 벡터 데이터베이스를 사용하지만, save_recall_memory 및 search_recall_memory 도구를 추가로 업데이트하여 그래프 데이터베이스와 상호 작용할 수 있습니다. 지금은 save_recall_memory 도구만 업데이트하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ca9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f3c7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class KnowledgeTriple(TypedDict):\n",
    "    subject: str\n",
    "    predicate: str\n",
    "    object_: str\n",
    "\n",
    "# @tool\n",
    "# def save_recall_memory(memory: str, config: RunnableConfig) -> str:\n",
    "#     \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
    "#     user_id = get_user_id(config)\n",
    "#     document = Document(\n",
    "#         page_content=memory, id=str(uuid.uuid4()), metadata={\"user_id\": user_id}\n",
    "#     )\n",
    "#     recall_vector_store.add_documents([document])\n",
    "#     return memory\n",
    "\n",
    "\n",
    "@tool\n",
    "def save_recall_memory(memories: List[KnowledgeTriple], config: RunnableConfig) -> str:\n",
    "    \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "    for memory in memories:\n",
    "        serialized = \" \".join(memory.values())\n",
    "        document = Document(\n",
    "            serialized,\n",
    "            id=str(uuid.uuid4()),\n",
    "            metadata={\n",
    "                \"user_id\": user_id,\n",
    "                **memory,\n",
    "            },\n",
    "        )\n",
    "        recall_vector_store.add_documents([document])\n",
    "    return memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83c3281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [save_recall_memory, search_recall_memories, pdf_retrieve, web_search_tool]\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# Create the graph and add nodes\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(load_memories)\n",
    "builder.add_node(agent)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add edges to the graph\n",
    "builder.add_edge(START, \"load_memories\")\n",
    "builder.add_edge(\"load_memories\", \"agent\")\n",
    "builder.add_conditional_edges(\"agent\", route_tools, [\"tools\", END])\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d017b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': []}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_zDJ5n3jwkQWHtFKTz3WOAY1n)\n",
      " Call ID: call_zDJ5n3jwkQWHtFKTz3WOAY1n\n",
      "  Args:\n",
      "    memories: [{'subject': 'Wonchan', 'predicate': 'introduced themselves', 'object_': 'Hi, I am Wonchan.'}]\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "[{\"subject\": \"Wonchan\", \"predicate\": \"introduced themselves\", \"object_\": \"Hi, I am Wonchan.\"}]\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Wonchan! How can I assist you today?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"3\", \"thread_id\": \"1\"}}\n",
    "\n",
    "for chunk in graph.stream({\"messages\": [(\"user\", \"Hi I am Wonchan.\")]}, config=config):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42f8d3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': ['Wonchan introduced themselves Hi, I am Wonchan.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_KAafUGDKnzp5QtEmr1i91Ghg)\n",
      " Call ID: call_KAafUGDKnzp5QtEmr1i91Ghg\n",
      "  Args:\n",
      "    memories: [{'subject': 'Wonchan', 'predicate': 'is non-tech but interested', 'object_': \"Microsoft's multi-agent strategy and tech stack like AutoGen.\"}]\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "[{\"subject\": \"Wonchan\", \"predicate\": \"is non-tech but interested\", \"object_\": \"Microsoft's multi-agent strategy and tech stack like AutoGen.\"}]\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great, Wonchan! Microsoft's multi-agent strategy and their AutoGen tech stack involve innovative technologies focused on enabling intelligent collaboration between AI agents. Would you like me to explain some of these concepts in non-technical terms, or is there something specific you would like to learn about?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"I am non-tech, but interested in Microsoft's multi-agent strategy and tech stack like AutoGen.\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b523c0",
   "metadata": {},
   "source": [
    "As before, the memories generated from one thread are accessed in another thread from the same user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06ebca1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': [\"Wonchan is non-tech but interested Microsoft's multi-agent strategy and tech stack like AutoGen.\", 'Wonchan introduced themselves Hi, I am Wonchan.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  bing_search_results (call_YTjtERjiXOdsq0XcFKjzMpM8)\n",
      " Call ID: call_YTjtERjiXOdsq0XcFKjzMpM8\n",
      "  Args:\n",
      "    query: AutoGen open-source framework hands-on website\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: bing_search_results\n",
      "\n",
      "[{\"kind\": \"web\", \"title\": \"AutoGen Studio — AutoGen\", \"snippet\": \"Caution <b>AutoGen</b> Studio is meant to help you rapidly prototype multi-agent workflows and demonstrate an example of end user interfaces built with <b>AutoGen</b>. It is not meant to be a production-ready app. Developers are encouraged to use the <b>AutoGen</b> <b>framework</b> to build their own applications, implementing authentication, security and other features required for deployed applications.\", \"content\": \" AutoGen Studio is a low-code interface built to help you rapidly prototype AI agents, enhance them with tools, compose them into teams and interact with them to accomplish tasks. It is built onAutoGen AgentChat- a high-level API for building multi-agent applications. See a video tutorial on AutoGen Studio v0.4 (02/25) -https://youtu.be/oum6EI7wohM  Code for AutoGen Studio is on GitHub atmicrosoft/autogen Caution AutoGen Studio is meant to help you rapidly prototype multi-agent workflows and demonstrate an example of end user interfaces built with AutoGen. It is not meant to be a production-ready app. Developers are encouraged to use the AutoGen framework to build their own applications, implementing authentication, security and other features required for deployed applications. AutoGen Studio offers four main interfaces to help you build and manage multi-agent systems: Team Builder A visual interface for creating agent teams through declarative specification (JSON) or drag-and-drop Supports configuration of all core components: teams, agents, tools, models, and termination conditions Fully compatible with AgentChat’s component definitions Playground Interactive environment for testing and running agent teams Features include: Live message streaming between agents Visual representation of message flow through a control transition graph Interactive sessions with teams using UserProxyAgent Full run control with the ability to pause or stop execution Gallery Central hub for discovering and importing community-created components Enables easy integration of third-party components Deployment Export and run teams in python code Setup and test endpoints based on a team configuration Run teams in a docker container Review project roadmap and issueshere. We welcome contributions to AutoGen Studio. We recommend the following general steps to contribute to the project: Review the overall AutoGen projectcontribution guide Please review the AutoGen Studioroadmapto get a sense of the current priorities for the project. Help is appreciated especially with Studio issues tagged withhelp-wanted Please use the tagproj-studiotag for any issues, questions, and PRs related to Studio Please initiate a discussion on the roadmap issue or a new issue to discuss your proposed contribution. Submit a pull request with your contribution! If you are modifying AutoGen Studio, it has its own devcontainer. See instructions in.devcontainer/README.mdto use it AutoGen Studio is a research prototype and isnot meant to be usedin a production environment. Some baseline practices are encouraged e.g., using Docker code execution environment for your agents. However, other considerations such as rigorous tests related to jailbreaking, ensuring LLMs only have access to the right keys of data given the end user’s permissions, and other security features are not implemented in AutoGen Studio. If you are building a production application, please use the AutoGen framework and implement the necessary security features. AutoGen Studio is based on theAutoGenproject. It was adapted from a research prototype built in October 2023 (original credits: Victor Dibia, Gagan Bansal, Adam Fourney, Piali Choudhury, Saleema Amershi, Ahmed Awadallah, Chi Wang). If you use AutoGen Studio in your research, please cite the following paper: To begin, follow theinstallation instructionsto install AutoGen Studio. previous ACA Dynamic Sessions Code Executor next Installation © Copyright 2024, Microsoft. Privacy Policy|Consumer Health Privacy Built with thePyData Sphinx Theme0.16.0.\", \"url\": \"https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html\", \"thumbnail_url\": null, \"source\": null}]\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You can try AutoGen hands-on at the [AutoGen Studio](https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/index.html). It provides a low-code interface for prototyping multi-agent workflows, building agent teams, and testing them interactively. It’s ideal for experimenting and better understanding the AutoGen framework. Let me know if you'd like further guidance!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"3\", \"thread_id\": \"2\"}}\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Recommend me a website where I can easily try AutoGen hands-on\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b78bec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node: load_memories\n",
      "{'recall_memories': [\"Wonchan is non-tech but interested Microsoft's multi-agent strategy and tech stack like AutoGen.\", 'Wonchan introduced themselves Hi, I am Wonchan.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  bing_search_results (call_pYjDSRklOEKy34SREElGGmwX)\n",
      " Call ID: call_pYjDSRklOEKy34SREElGGmwX\n",
      "  Args:\n",
      "    query: current popular multi-agent frameworks from companies\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: bing_search_results\n",
      "\n",
      "[{\"kind\": \"web\", \"title\": \"Multi-Agent AI Systems: Frameworks, Use Cases &amp; Trends 2025\", \"snippet\": \"Why <b>Multi-Agent</b> Systems Matter in 2025? The rise of <b>multi-agent</b> AI systems is becoming increasingly important in 2025, driven by the growing complexity of enterprise infrastructures, global markets, and the demand for real-time decision-making. Traditional AI models often struggle to scale and adapt in highly dynamic, <b>multi</b>-variable environments—this is where <b>multi-agent</b> AI <b>frameworks</b> truly ...\", \"content\": \"Multi-Agent AI Systems: Frameworks, Use Cases & Trends 2025 As artificial intelligence continues to evolve, one paradigm is quickly gaining traction across industries:multi-agent AI systems. But what is multi-agent AI, and why is it becoming so pivotal in 2025? In simple terms,multi-agent AIrefers to a system composed of multiple intelligent agents that interact, collaborate, or compete to achieve individual or shared objectives. From robotics and logistics tocybersecurityand finance, multi-agent AI frameworks are transforming how complex tasks are executed. This article exploreswhat is multi-agent AI, howmulti-agent systems in AIoperate, and the growing impact ofmulti-AI agent systemsacross sectors. We’ll also dive into architecture, use cases, and emerging trends to help you fully understand the potential and challenges of this powerful AI approach. At its core,multi-agent AIis a branch of artificial intelligence in which multiple autonomous agents operate in a shared environment. Each agent in amulti-agent system in AIcan perceive its environment, make decisions, and take actions to achieve specific goals. These agents may operate independently or interact with one another to collaborate or compete. Key Features of Multi-Agent AI Systems: If you’re wonderingwhat a multi-agent system is is in AI, think of it as a team ofAI-powered individuals—each with its own goals and behavior—working toward a larger mission. The rise ofmulti-agent AI systemsis becoming increasingly important in 2025, driven by the growing complexity of enterprise infrastructures, global markets, and the demand for real-time decision-making. Traditional AI models often struggle to scale and adapt in highly dynamic, multi-variable environments—this is wheremulti-agent AI frameworkstruly excel. By leveraging autonomous agents that operate independently yet collaboratively, multi-agent systems in AI offersignificant benefits: These advantages make multi-agent AI a vital component of modern, intelligent systems in enterprise and industry use cases alike. To build an effective multi-agent AI system, the architecture must support communication, coordination, and decision-making amongagents. The core entities that act based on internal states and external observations. The space (physical or digital) in which agents operate. Mechanisms for information exchange between agents. Rules or strategies that govern how agents interact. AI models that allow agents to adapt based on feedback (e.g., reinforcement learning, deep learning). Middleware or platforms likeJADEorSPADEprovide tools for building, deploying, and managing agent-based systems. Multi-agent AI systemsare making significant strides in the real world, particularly in industries where automation, coordination, and rapid decision-making are critical. In the field ofautonomous vehicles, multiple self-driving cars act as intelligent agents, interacting with each other and traffic infrastructure to optimize traffic flow, reduce congestion, and enhance road safety. Similarly,smart gridsutilize energy agents to manage power generation, distribution, and consumption—leading to more sustainable and efficient energy use. Inlogistics and supply chain management, multi-agent systems streamline operations by enabling warehouses, delivery trucks, and inventory systems to act independently yet collaboratively. These AI agents dynamically optimize delivery routes, restocking schedules, and resource allocation, significantly reducing operational costs and improving responsiveness. In the realm ofcybersecurity, intelligent agents work together to detect anomalies, neutralize threats, and provide real-time system protection, making organizations more resilient to cyber attacks. Financial marketsare another area wheremulti-agent AI thrives. These agents analyze live market data, execute trades, and apply hedging strategies autonomously, enabling faster, more informed trading decisions. Ingame development and simulations, multi-agent systems power strategic AI opponents and complex scenario modeling for training, planning, and forecasting. These real-world applications illustrate the transformative potential of multi-agent AI systems across diverse sectors. In enterprise software development,multi-agent AI systems bring automation, modularity, and real-time decision support. B2B platforms integrating multi-AI agent systems can benefit in areas like: By embedding multi-agent AI frameworks intotheir ecosystems, B2B software companies can offer smarter, more responsive, and scalable solutions. Despite its advantages, building multi-agent AI systems comes withhurdles: These statistics reflect the accelerating momentum behind AI adoption, particularly in multi-agent systems and enterprise applications. As organizations seek smarter automation and real-time intelligence, AI agents are becoming integral to driving efficiency, scalability, and innovation. The following trends highlight just how transformative multi-agent AI technologies will be in the years ahead. Understandingwhat multi-agent AI is is crucial for staying ahead in the era of intelligent automation. As enterprise systems become more dynamic and data-driven, the need for scalable, distributed AI solutions grows. Multi-agent AI systems, with their ability to collaborate, adapt, and optimize in real-time, are positioned to play a central role in the future of AI. Whether you’re a B2B software provider or an AI strategist, now is the time to explore the potential of multi-AI agent systems. From logistics and fintech to cybersecurity and robotics, the adoption of multi-agent AI frameworks is no longer a trend—it’s a necessity for innovation in 2025 and beyond. For deeper integration and enterprise-grade applications, consider partnering with experienced AI developers or using open-source multi-agent system in AI tools to accelerate your implementation. Eastgate Software We Drive Digital Transformation Eastgate Software We Drive Digital Transformation. Case Studies Company Contact Copyright © 2024.  All rights reserved. Support(+84) 246.276.35661 \", \"url\": \"https://eastgate-software.com/multi-agent-ai-systems-frameworks-use-cases-trends-2025/\", \"thumbnail_url\": null, \"source\": null}]\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Besides Microsoft's AutoGen framework, you can explore other multi-agent strategies through prominent systems such as:\n",
      "\n",
      "1. **JADE (Java Agent Development Framework)**: A well-established framework for developing agent-based systems. It allows agents to interact in various environments supporting collaboration and communication.\n",
      "\n",
      "2. **SPADE**: Another multi-agent platform focused on scalable, distributed applications. It is used for real-time systems like logistics, smart grids, and cybersecurity.\n",
      "\n",
      "3. **Eastgate Software’s Insights on AI Trends 2025**: This resource highlights how multi-agent systems integrate smart coordination mechanisms in industries like autonomous vehicles, fintech, and energy.\n",
      "\n",
      "You can search further about these platforms to dive deeper into various companies' approaches to multi-agent ecosystems. Let me know if you'd like a specific direction or starting material!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"3\", \"thread_id\": \"2\"}}\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"Recommend other multi-agent frameworks to me inorder to learn about other companies' multi-agent strategies\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5051041a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='3f669daa-6568-494d-a67f-ab5859268c2d', metadata={'user_id': '3', 'subject': 'Wonchan', 'predicate': 'is non-tech but interested', 'object_': \"Microsoft's multi-agent strategy and tech stack like AutoGen.\"}, page_content=\"Wonchan is non-tech but interested Microsoft's multi-agent strategy and tech stack like AutoGen.\"), Document(id='649391d9-e34f-42d2-8239-d68637c5f666', metadata={'user_id': '3', 'subject': 'Wonchan', 'predicate': 'introduced themselves', 'object_': 'Hi, I am Wonchan.'}, page_content='Wonchan introduced themselves Hi, I am Wonchan.')]\n"
     ]
    }
   ],
   "source": [
    "records = recall_vector_store.similarity_search(\n",
    "    \"multi-agent\", k=3, filter=lambda doc: doc.metadata[\"user_id\"] == \"3\"\n",
    ")\n",
    "print(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "564738b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFPCAYAAABklUYjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAAxOAAAMTgF/d4wjAABEkElEQVR4nO3dd3hU1dbH8e+ZSSUJIaGF0IvSRFCqWMAGWLAh7bXgVUQhYi9YEFDvtSOKiKIi2PCC2EERFFRQQEBQES5dIaETYhISJpnZ7x+bSQgdycyk/D7Pw5PMmTnn7ElhZe2ytmOMMYiIiEip4Qp1A0REROT4KHiLiIiUMgreIiIipYyCt4iISCmj4C0iIlLKKHiLiIiUMmGhbsCBsjz5rE3PZkNGDmDwBmAhm9sBcKgXH03DhBhiI0rcl0FEROSwnJKyztvj9bF0awapmbk4DviC0CqXA8ZArbgoWlaPJ8KtjggRESn5SkTw3pyVy+LNu8k3JihB+0AuB8IchzY1KpEUGxX8BoiIiByHkAbv/bPtkP8FATgoCxcRkZIvZMF7xx4P81N3hSzbPhx/Ft6hZiJVKkSEujkiIiIHCUnw3pKVy/y09BIVtA/kcqBDcoK60UVEpMQJevBOzcxhYdruEtFNfjQO0C65EjXjokPdFBERkQJBHdjdkpVbagI3gAEWpu1mS1ZuqJsiIiJSIGjB245xp5eawO1ngPlp6ezY4wl1U0RERIAgBW+P18f81F34gnGzAPAZmJ+6C4+3tL4DEREpS4ISvJduzSA/9MvJT0i+MSzbmhHqZoiIiAQ+eG/OyiU1M7dEzyw/Fj4DmzJzNf4tIiIhF9Dg7fH6WLy59ExQOxoDLNq8W93nIiISUgEN3mWhu/xA6j4XEZFQC1jwzvLkl4nu8gP5u8+zPPmhboqIiJRTAQvea9OzcZxAXT20HMe+PxERkVAISPDO9xk2ZOSUuazbz2dgQ0YO3rL6BkVEpEQLSPDelJkDZWaa2uGYfe9TREQkuAISvFfvysZbxmO318CqXeo6FxGR4Cv24J2xN6/cTObK8uSTsTcv1M0QEZFyptiD984cD66yOlPtAC7HYVeOgreIiARXsQfv9Jw8vGVsbffheI1hV442LBERkeAKSOZdnuzMLV/vV0REQq9Yg7fXZ8jO8xbnJUu8bI9XS8ZERCSo/nHwHjVqFMOHD2f37t0Fx/72HP/474JZX/Lf0c+xfsXv/7QpIff3vgl6ffr0wXEcJkyYcMjXTZgwgeHDh7Nhw4YTvucNN9xwxHsdj+HDhzN8+PATvg5AvXr1cBznmN7jge9h/3M3bNiA4zjUq1evWNq1//0cx2Hu3LnHde6hft6PJicnh2HDhtG0aVOioqKIj4/n1FNP5bHHHjvOlouIFHVCwXvEiBFFg/fefFz7zVXz5h991vnCWTOYPGYk61cs/6dNCSmXA38f44zzCRMmMGLEiGIJ3sVpxIgRjBgxItTNYPTo0UyaNImqVasW+7WzsrL48MMPcbvdAMf9R8+hft6PJD8/n/PPP5/HHnuMqKgonnrqKZ566ilat27Nxx9/fJytFxE5gDmKRo0amYiICBMfH2/at29vtm3bZurWrWuwVVgK/hljTM3adQxgLr9poKmaXMuce2UvM+brH039ps1NVIUYExEZZZLrNzQDn3jOTF2ZZjpf0eug64yY+KF5/5c1BdeIjI429ZudYh4cO9FMXZlmpq5MMyn/ecEkVq9hYuMTzDV3PVhw7tSVaeaU9mcawDz/6SwzdWWaef7TWQYwp3Y8u+D8/f+17HiOiY1PMGHh4Saxeg1zyfX9zeTlG4u074Ke15gGzVqYqAoxpt0F3cykZevM1JVp5uUZ80zT09uaqOho0717d9OlSxcDmLfeeuugr2OnTp0Oeq/r1683O3bsMP379zc1a9Y0sbGx5qyzzjI//vhjwXnTpk0zHTp0MHFxcSYuLs6kpKQYY4zp16+fAcygQYNM27ZtTWxsrLniiitMTk7OIb+PTz/9tKldu7YJDw83iYmJ5uyzzzbGmIPaVLduXWOMMTfccIOpVq2aCQ8PN9WrVzf9+vUzf//9tzHGGJ/PZ0aOHGmaNGlioqKiTLVq1czEiRONMabgZ2P9+vVmwYIFplKlSiYpKcksW7bsoDb534P/67X/uevXry/SnldffdU4jmPOPPNMk56ebn799VfTrVs3k5CQYCpXrmx69uxpNm3adNif47feessAJiUlxVSpUsXExcWZ7Ozsguf979//9du/LYf7eV+3bp3p0aOHqVq1qomPjzfnn3++WbJkiTHGmHfeeccApmHDhiY3N7dIW/xfR2OM+f77783ZZ59tKlasaJKSkkz//v1Nenp6ka/PzTffbE4//fSjfo9FpPw4auadnZ3N2LFjeeKJJ2jcuDH5+fmMHj2aKlWqAPDSSy8xadKkIucsnfsdVw+8gzO6XorLHUaHLpfwr4dG0Of2+3C5XLz26P2krltD177X06xNBwC69Lmeu55/hdqNTmbiM4/z6Ztjad6uI1cPvBOf18ezt/fnr1Ur2bR2NWOH3ktudha9b7ubVcsWF7n35TcNBODLd98C4PvPptrr977+kO/v5Fatufaeh+j3wDDqNm7KtLff4NupHxR5zZLvvuGCXtdQOakGC2d9xdxpn9r3fv/trFjyM5f17M1ZZ53F7NmzD/t1fPTRR2natCkAQ4cOLcgwr7vuOsaPH89VV13FkCFD2LhxIxdffDHbtm1jwYIFXHbZZSxfvpwHH3yQZ599lmrVqhW57ieffMKNN95IrVq1+OSTT/jggw8Ouvfu3bt54IEHiIuL4/XXX2fo0KHUqFEDoMj3btKkSYwePRqAFi1a8NhjjzFq1CjOP/98Jk6cyFNPPQXAyJEjufvuu/F6vbzwwgvcf//9BRmt3/z587nwwgtJSEhg7ty5nHrqqYf92hzNK6+8wsCBA+nWrRtff/01juPQtWtXFi9ezODBgxkwYACfffYZPXv2POw1/Jn2TTfdRO/evcnMzGTq1KnHdP9D/bx7vV4uvfRSpk6dyvXXX8+DDz7I999/T9euXdm5cyfz588H4OKLLyYyMhKv18uOHTvYsWMHe/fuxev1sn79ei666CLS0tK499576dWrF2+88QaDBg0qcv9p06Zx8803H/F7LCLlzNGie3h4uOnRo4cZNmyY+f777wuO75+Z+CXvy7wff/fjgsz2penfm5NbtjYul6tI5nL3yLFFstuU/7xQcE585SoHZTqAuWHIcHPTw48XZMNTV6aZcd8tLpJ5T12ZZuqc1MRERkebCT/9bion1TCJ1ZLM5N//Oijrfv+XNabjRd1NeERkkft06XN9kbZdd98jZurKNHPVLbcbwPS49Q7z7qJVBjCR0dHm9627jTHmiJm3MYXZ9+zZs40xxmRlZRnHcQ75Xj/66CNz//33G8AMHTr0oGv5s7JnnnnGGGPMQw89ZADz8MMPH/TavLw8U7t2bRMXF2f69u1r/v3vf5tffvml4Hn/Pf28Xq8ZNGiQiYmJKdKmbt26GWOMadeunQHMN998c9C9/D8X4eHhplatWiYtLe3QP1jm2DLvsLAwA5iuXbsaj8djjDFm+vTph/yaAWbXrl0H3WfdunXGcRzToEEDs379ejN58mQDmHPPPfegr8GhMu9DPV6+fLkBTKNGjQqucemllxZ871JSUgxgBg8ebIwxZsWKFUXauWLFCvPKK68c8j1UrFjxuL/HIlK+HDXznjhxIo0aNeLDDz/knHPO4bPPPgPAOUQhFv+RKknJBccmjxnJqmWL6XT51Qx9433anHshAHtzc/dd5/D3vnfUOB4d/0HBP/+5h7u/32U33srenBxGP3gnO7ds5ryr++AOCzvodd999hE/fvk5dRs35aFX3+bqgXcC4NnXNr+KCZUBCNt3Da+3cCzfGIP7GGvSHK7N0dHRzJgxg5kzZxb8a9eu3TFd0z8+HB4eDtix1gOFhYWxbNkyXnzxRWrUqMFrr71G69at+eWXXw55zVmzZvHKK6+QlJTExx9/XJCN5+Qcey33GjVqkJqayhdffHHM5xxKdHQ0lSpVYv78+SxbtqzIc23bti3yNZsxYwbR0dEHXWPixIkYY1i3bh3169enV69eAMyZM6dg/oG/5yA/Px+fz3fQ2Pbhvnf7H9//8zPOOAOAL7/8Eo/HQ506dZg5cybVq1c/6Brdu3cv8j6mTJlS5PnDfY/z8/PJzc095PdcRMq2owbvrVu30rx5cxo0aADAX3/9BUBiYiJguyOnT59+1Bvtycokdd0aVixeWOR4bHwCAEu+/5a50z7BszeXDl0uAeDrye+wc8tm1q/4nckvP8+urVs4teM5uNxu5n35GdPfHc/rIx486F5nX3olidVrsHjOLFxuNxf2vOaIbfPk5rJr21YWzvrqqO/DLzo2lsatWuPJzWX4vXfy7LPPHrHbHAq/ZlOmTGHKlCnExMTQrVs3cnJyePPNN9m0aRMLFy7knnvuIS8vjyuvvBK3282oUaN48sknGTdu3D+aqZyZmUlKSgp79uyhVatW1KpVC5/PR2pqapF2jRkzhu+++67gvNzcXLZt23ZQMPF3T9966628+uqrjBw5knfffbfIaz788EMaN27MLbfcwvjx44+7zX6JiYlMnz6d/Px8unTpwi+//ELHjh2pUaMGixcvZvbs2WzcuJGZM2cybNgwoqKiipxvjOHtt98G4J133uHjjz/m448/pl+/fhhjmDhxIgANGzYEbLf4kCFDyMjIOKgdUPjz3rhxY5o3b87q1au5//77eeaZZ5gxYwZVq1blnHPOoXfv3nTs2JE1a9Zw5plnMn78eDZu3MjevXsLrtmtWzdiYmL45ptv+Pnnn9mwYQOffvopr7zyyjF9bZ544gmio6N55JFH/tkXV0RKr6Ol5klJSSY8PNxUqVLFXHvttSYzM9MYY8x///tfk5SUZADTuHFjY0zhhLWxsxYUdE2P/vIH07D5qSY8ItK06HCWOeeyHkW6yUd9McfUanSycbndBjBv/LDUvP/LGnNF/0GmWq06Jjwi0iRWSzIdulxixn6zsMiEtcRqSQVd2bHxlYp0iV9378MGMG3P63LIiWpTV6aZ95euNe0u6GYioqJMzQaNCq7V+Ypeh+zS75VytwHMFTenFExYa3JaGxMbF2e6detmzjvvvCN2m8+ZM8fUq1fPOI5jIiMjjTHG7NixwwwYMMDUqlXLREZGmrp165prr73W7N5tu+I/++wz0759exMbG3vICWv+ew0bNswA5oEHHjjovnv27DHnn3++qVKligkLCzNJSUnm9ttvN3l5ecYYY0aNGmUSExMLuqd9Pp8ZMGCAiYmJMXXq1DH//ve/DWA6depkjLHd6s8884xp3LixiYyMPOyEtU2bNpn69esbl8tlJkyYcFC7jmfC2jfffGOioqJMYmKiWbp0qfn111/NJZdcYipXrmwqVKhgmjVrdsjhhdmzZxvAtGrVqsjxRYsWGcDUr1/f+Hw+89VXX5k6deqYxMREk5KSYmrUqFGkm/xQP+/r1q0zV111lalSpUrBhLXFixcX3CM7O9s8/PDDplGjRiY8PNwkJCSYVq1amQceeMBkZGQYY+yEtU6dOplKlSqZ2NhYc9ppp5nRo0cf0/f4SN9zESnbHGOKr5Zpeq6HOX/uDPhmoLM+fJ/4xMpEREYx55MpfP/5R3S6/Gpuf/olAP5YtICvP3ibH774mOETJtOiw1kBa4sDdK5bhYSo8IDdQ0REZH8HDwSfgIoRwQlgf61ayXefTiV3TzaJ1apzab+b6TP4voLnh157JVEVYrji5pSABm6/ihHF+mUUERE5omLNvAG+XreNrHJUIjU2wk2X+tWO/kIREZFiUuwbk1SOjijuS5ZolaPK1/sVEZHQK/bgnRAdjruc7OftdhwSy9kfKyIiEnoBybx95WQ/b58xJEZropqIiARXsQfv+MhwYsvJBK7YiDDiIxW8RUQkuIo9eAOclBhzzFXHSiu3AycnxoS6GSIiUg4FJHjXioumsFhqWeXse58iIiLBFZDgHeZyqBcfXWRv77LE5UC9+GjcZfUNiohIiRaQ4A3QMCGGsjpvzRj7/kREREIhYME7NiKMWnFRZS77djlQKy6q3EzKExGRkidgwRugZfV4wsramm+vl5PiNMNcRERCJ6DBO8LtonWNSmVm6prPm8/jt/YjoWIc8fHxNGvWjMsuu+yw+2KLiIgEQrHXNj+UhWnppGXl4ivFY+AuB6pGuLmwWT1ycnKKPDdv3jw6duwYopaJiEh5E9DM269VGeg+D3Mc2tauwsiRI4mMjCw4fuGFFypwi4hIUAUleEe4XXSomVhqJ6+5HOhQM5EIt4v+/ftTu3ZtABISEliyZAk9e/Zk27ZtIW6liIiUF0EJ3gBVKkTQITmh1I1/O0CH5ASqVLAbkISFhfHaa6/hcrn45JNP+OOPPzDG0Lx5cyZPnhzaxoqISLkQlDHv/aVm5rAwbTelYfjbAdolV6LmISqp7dixgypVqhQ8njx5MikpKXTu3JkxY8ZQrZr2+BYRkcAIevAG2JKVy/y09BI9gc12lSeQFBN1zOds27aNQYMG4Xa7mTRpEi7XITo2Ro6E6GgYOLAYWysiIuVJSII3wI49Huan7iLfmBIVxF2OnZzWoWZiQVf58crNzSUq6hBBPyMDIiNhxw6oVesEWyoiIuVVyII3gMfrY+nWDFIzc0tEN7qDrZ7Wsno8Ee4ATAeIjoZx4+C66wqPeb3gdhf/vUREpMwKafD225yVy+LNu0OWhfuz7TY1KpEUe+zd5Mfl3nthxgz47Tf7eOVKaNLEfq4ALiIix6FEBG+wWfiyrRlsyszFcQhKEHc5dpORgGbbAEuWQNu2sGgRnHYa3HwzrF5tu9DHjYO6dQNzXxERKZNKTPD2y/LkszY9mw0ZOYDBG4DWuR0Ah/qVomlQKSbwm4ycdBL06QOPPw6//ALnnAN//QXTpsEjj8Dbb9tjIiIix6DEBW8/r8+wKTOHVbuyyfLk43IcvCfQVLfj4DOG2IgwTk6MoVZckPbjfvFFeOIJ2L4dPB6IiIDbb4f69eGuu2wwP/lkiNEWoyIicmxKbPDeX8bePHbl5LErx8POHA/ZeV6Agopt+78Bfzj2d7vHRLipHBVBYnQEidHhxEeGYEew7duhUiX48EPo2xfS0mxAv+oquOCCw5/n88GhlpuJiEi5ViqC94G8PsPfnnz+3ptHvs/gM7Z73e2Ay3EIczlUjAynYkRYcLLrY5GRYQN3dLQN4tddB/n58MEHha/xB+tff7VLyRIT7XFNaBMRkf2UyuBdqj35pA3eNWvC9dfD1Vfb4/7AnZVlJ7TFxsLll8Oll9rnjYFSvrmLiIgUDwXvUNi82Qbq6tXt4/0D86hR8N//QvPmsGePzdjfegtUblVERPbRgGoo1KhRGLjBBm+AH36A+fPhX/+CN96A99+HvXvh44+Lnq+/t0REyjUF75LA5YLdu2H8eGjYEM4/3x5fu9aOde+fdefnF2bpXm/QmyoiIqEX4AXOcszWrLGBuWNHG8ABpk6FOnWgTRtYvx7mzIEff4R27ey4uCaxiYiUSxrzLkkyMqBCBQgPh48+gs8/h27d7JKybt0gKQnOPNMWd6lSBcaOta8HTWgTESlH1G1eksTH28C9ezfMnGkfX3ml3Ua0alV46SUYNMgG77/+gg0bCs91HI2Fi4iUEwreJVGlSjB8uJ24FhFhi7y0bAkJCfb5RYvs0jJ/t/ljj9mAr7FwEZFyQWPeJVX16oUz0itXhtTUwoltS5bY52rXhgkT4PXXITvbllm96SaNhYuIlHEa8y4NNm60WXhMDOTkQFwc3HKLDdbXXgtNm9rqbc89Z2emv/oqRAVoa1MREQk5Be/S5L//tVn1+efbLvTrrrOV2m67zZZT3bjRVmSbPbuwtKqIiJQ56jYvTXr3Lvx8+HA7Fn7HHTZwA7z8MrRoYUur7j/73F96NTtbu5eJiJQBmrBWWjVubGujN21qH3/+OaxeDT162ElujmPXjYMN3F6vzdyXLNGENhGRUk6Zd2nVt2/hbmNbttj65x06wIUX2tnobdpAWJjNulevhvvvt68/4wxNaBMRKeWUeZdm/iC8Zo0dA+/UyXaZP/mk3Sf8998Lu8vXr4dly+Crr0LbZhEROWGasFZWZGXZ8Wz/OPcbb8C2bXDvvXDXXbbIS4cOtsDLddfZEqt+2i9cRKRUUfAua/LzbXe53/jxMGuW7Wbv3t0ey8iAtDS7dvyCC+wx/6Q2EREp8RS8y7L0dHjwQTj9dJttR0fD3Lnw7rs2WOfm2kA+erTdAEVEREoFpVplWWQkbNoEK1bYwJ2eDm+/bfcM373bfn7llfDww6FuqYiIHAcF77KsQgVbdW3TJpgyxWbaa9bYjU6aNrUzz/futevFt249+HwtKRMRKZHUbV5eZGTYMe3u3eHbb+3nP/0Et94K9erBp5/a2elLlth14n362PO01aiISImj4F2e5OfD4MF2otorrxRWZvP54Jln7DakdevayWzR0fDii3YsfPduWLzYlmUVEZGQU7d5eRIWBmPHwjnnQJcu8NRTkJdna6HPn2/HvsePt2vBW7SAjz6y582caSe8rV4d2vaLiAigCmvl0733wlVXwapVEB5ui7jk59uA7e8mf+wxO+a9ejW8/77d/OSkk+z5WhcuIhJSyrzLqwYNoFs3+3l8vA3iVavawO2fqJadbbvTFy6EzZttCVZQ4BYRCTEFb4FTTwWPB3r2tJPW3G4bwGfOhDlz7P7gDz5ox8CHDg11a0VEyj0Fb7F10adNs5uZPP64HQdfvRpee83ORu/eHZKT4b77IDNTS8hEREJMs82lqJwciIqC/v3t+vAZM+zxrCy48UaoUcNm4H7+sqrz5tla6ldeGZp2i4iUI5qwJkVFR9uPZ58NrVvbz42xk9Z+/x0mTLDHfD47Pu5ywZ499rjLZUux1q0bipaLiJQbCt5yaDfcUPj5b7/ZbUZHjbJV2w6cbT5xou1qv+KKwsCtjU5ERAJG/7vK0W3YYDPxyy+3j91uG5wBFi2ypVdXrbIbnLz8sj2uwC0iEjAa85bj4/XawOw4trv87rtt1v1//wft20PXrnD99XDLLYVrxpWFi4gUK/2PKsfH7S6sdT55MqxbB1dfbUunxsbaGes7dtjnd+60HxW4RUSKlf5XlX/m999tKdUtW+DCC+2xnTtttu1y2Y8PPABjxtjqbf4OHnX0iIicMAVv+WdOOQWGDYOGDeHjj+2ysnHj7AYm11wDn31mu9UrV7Y11f3Zuv+jgriIyD+mMW85Mf/7HwwcaPcKb97cbiXaooXdvax9e7jpJlt+9auvbLaekmKXoy1aBFWq2O1IRUTkuGipmJyYxo3t/uCrVxduXDJmjF1Sdv75NnBv2wazZsHff9tZ6QsWwIoVcMEFdstRjYmLiBwXBW8pHv7ADba7PCICWra0jz/6yE5iGzAAkpLgP/+xs9Z79FDgFhH5B/Q/pxS/evVsNv7pp/DCC3ZMvE0b6NjRbnRy7rl2Sdmjj9os3E8jOCIix0Rj3hIYK1fCK6/A/Pl217KRI2HtWlsXvWlTOxN92zY7Ez05uei5s2bZLnURETkkdZtLYDRpAi+9ZDPwvXuhYkX45BM7Wa1HD/uaatUKX79/QZe//oK5c+Gss0LSdBGRkk7BWwLrvPMKP1+50nadN2pU9DX+Cmy//Waz7ttuK1xSdmAddRER0Zi3BNFZZ8Hbb8M33xQe8xd1AfvcwoWwcaPN1qFoHXUREQEUvCWYBg+GqVMLtx2Fwgz7nXds0L72WmjQwHa5P/+8naXuD+4K4iIigLrNJdjq1SsszJKfb6uvrVxpi7icfrqdhf7DD3amuuPA7Nlw0UW2uIuWlYmIAAreEkph+378nn/eFnXp2dNm2lOn2iptjz8OcXHQtq3d9KRfP/v6NWtsIG/QIHRtFxEJIQVvCb3LLrMf69e33eW7d9uyqklJ4PHAaadBeLh9zXvvwfLltihM/fqF3e4iIuWIgreEXvfu9uPixTBzpl3jffbZ9tiMGXZSW5UqNqgPHw7p6fDhhwrcIlJuqUiLlCyzZ9uiLpUrw6+/wptvQmQkPPOMrcb27LMQFQXr19tudf9SNP86cRGRckCZt5Qs555rP2Zm2klraWk2YG/ZAm+9ZbvSX34ZUlMLx8z37LFj5qB14SJSLih4S8kUF2fHumvVsrPTX33VLiV75hn7fM2a8Pnntlb6ihVw6aUwaJACt4iUC1p7IyXXpZfCv/5lP//+e2jXzu4Znp9vdyq74w7IyYEpU2DePDsbPS+v8HyNCIlIGaXgLaXDOefY2uiffGK7yydNsl3s69fD0KG2S93rhe3bC89xHAVwESmTFLyldLj1VpthV6gAubm2Dvozz8CXX9pg7t+GtFo12LkTBg60a8Y1iU1EyiDNNpfSKSXFjoc/+KB9vHw5rFoFV15pA/24cTBkiA3qAwaEtKkiIsVNwVtKpzVr4PbbbfGWlBTo0sUe/+ILuPpqu8lJo0YwcSLcfDOcckrhuZqRLiKlnIK3lG7PPmuXk73wgi3ecuaZcMstdjIb2N3JJk60r0lOLszCtS5cREoxBW8p/fLybAZ+9dV2/fdPPxU+17Mn/PmnLfby/PN2Qts770BiYujaKyJygjRhTUo/f93zTp3ggw8Kj48bZ8urVq1qg/eECdC4sV12tj9tNSoipYyCt5QdgwdD3bp2TBtgyRIYMQKmTbO7kJ16qh0T93eXL1kCW7cWbjXqP09EpIRT8Jayxz8Z7bzzbH10gJEjbeZ98cVQuza89hrcead9zZgxRc/Lzw92i0VEjouCt5RdZ58N27ZBjx6wdCmcfjqMGmXLrr75Jlx1FSxbZteP33NP4XnjxtmxcxGREkoT1qTs8xdzee45uwd4YqLtPv/sM7tOvH59Oxt9wQK76UlmJixcGOpWi4gcljJvKfvuv9/WQm/c2FZhW7bM1k1v2RJefNG+JjnZLh+bN89uipKVFdo2i4gcgYK3lA8JCRAbC7t3Q+/eNutu0AAmT7bLx3JybGZ+zz12ydm11xY9XzPSRaQEUbe5lD8rVtgiLm63XV42ZIjd3OSTT2zNdD+Px054S062/8AGcZf+5hWR0FLwlvJr40Y783zTJpuF//KL3XIUYNYsGDYM+vSB99+32fqdd4a0uSIifkohpPyqXdt+XLECWrSwm5gA7NkDffvCypV2Mtu8eTB3rq3Mtj/93SsiIRIW6gaIhNyFF8KiRdC6Nfz8M4weDa1a2c1NevWygbtKFcjIKHqe49iu9YiIkDRbRMovZd4iYJeM/fCDnWl+yim2G71GDXssLMwG8AoV7GtnzICXXoK1a23gzsy0m5+EmNdnSM/18GfGHtamZ7NqVxYrd2axalcWa9Oz+TNjD+m5Hrw+9RiIlHYa8xY50LJldvexW26BG2+0x1JTITsbxo6FmTPhnHNsjfSXX7ZFXtavtwG8atWgNTNjbx47czyk59iP2Xm2vKtrX/XX/X+x/fun+eN2TLibytERJESHUzk6gvjI8KC1W0ROnIK3yKGsXAl33WV3LHvySWjb1m568sQT8NVXUKsW/P67fY3LBcOHwxlnBLxZ+T7DpswcVu/KJsuTj8tx8J7Ar7DbcfAZQ2xEGCclxlA7Lhq3S1ulipR0Ct4iR/LBB9Cune1Gb90arrkG7r7bPrd+PZx8sl0f3r8/xMQErBlZnnzWpmezISMHMHgD8FvrdgAc6sVH0zAhhtgITYkRKakUvEWO1e23wyWXQNeu9nFKii2rOm5cwLrLPV4fS7dmkJqZi+MUdnsHksuxE+lrxUXRsno8EW5NjREpafSntcixOu00Ow7++ON2O9Evv4R33w1Y4N6clcvizbvJNwZD8Fam+f9ASM3KZWv2XtrUqERSbFRwbi4ix0R/Uoscq3/9yxZvWb0aXn/dTmpr167g6dzcXJYuXXrCt/F4fSxMS2d+ajoenwlKtn0oPgMen+Gn1HR+TkvH41WJWJGSQt3mIv/E7NnQqFFhoRdg165dNG3alHPOOYcxY8ZQrVq1477sjj0e5qfuIt+ELmgfisuBMMehQ81EqlTQunaRUFPmLfJPnHtukcANkJiYyG+//YYxhubNmzN58uTjuuSWrFzmbtoZ0mz7cPxZ+NxNO9mSlRvq5oiUe8q8RQJg8uTJpKSk0Llz52PKwlMzc1iYtpvS8MvoAO2SK1EzLjrUTREpt5R5iwRAr169WL58+TFl4VuycktN4AZb/GVh2m5l4CIhpMxbJMCOlIXv2ONh7sadlMapYC4HzqpVWWPgIiGgzFskwA6XhXu8Puan7iqVgRvsOPj81F2ahS4SAsq8RYJo/yz8npFj2ZKTV+Impx0PlwM1Y6Nom5wQ6qaIlCsK3iJBtm3bNsa9P4XmF11Vasa5j8QBzqiZoEIuIkGk4C0SZB6vj6/XbcNTmlPuA0S4HLo0qKZSqiJBot80kSBbujWD/DL2N3O+MSzbmhHqZoiUGwreIkGU5cknNTO3VI9zH4rPwKbMXLI8+aFuiki5oOAtEkRr07Nxyuh22Y5j35+IBJ6Ct0iQ5PsMGzJyylzW7eczsCEjB29ZfYMiJYiCt0iQbMrMgTIxv/xIzL73KSKBpOAtEiSrd2XjLeOx22tg1S51nYsEmoK3SBBk7M0rN5O5sjz5ZOzNC3UzRMo0BW+RINiZ48FVVmeqHcDlOOzKUfAWCSQFb5EgSM/Jw1vG1nYfjtcYduV4Qt0MkTJNwVskCHaWs2C2M7d8vV+RYFPwFgkwr8+QnecNdTOCKtvj1ZIxkQBS8BYJsL89heO/E54aQY8myXzyxhgA8jx76duyAT2aJPPb/LkAbFi5nB5Nkrnvqq4Bac+2TRvp0SSZW89rF5Dr+/1dTiboiYSCgrdIgP29Nx/Xvrlqzdq2B+CPRQsAWPPbUjx7cwFYse/YHz/PB6Bpm/ZBbmnxcTnwt2aciwRMWKgbIFLW5e/Xfdy0dXscx+F/vyzCGMOKRQuJiIqiYfNT+WPxvuC9L4g3bd2en2ZMY+prL5K2fi1xlRJof+HF9L3jAaJjYhg95E7mfDKZC3pew7rlv5K2YR2ndjybu55/hYjIKLIydvPBS8/y8+yv2b19O5WTavDAy+OJjokFwOfzMuGpEXz/+VTCwsMZMOwp2px7ITlZWYy4sTep69fiyc0lsVp1Luh5DT1uvR2AR6/rwfKff+LSfjfzyw+z2bV1C2defDkDH3/2sO9bRIqXMm+RAPMaU1BXLa5SArUbNSYrYzd/rVrJH4sXcNKpp3PqGWezetkS8vPyWLEviFdMSGTkXbeQvn0b/R4YRsNTWjLt7TcY/+9Hilx/yXffcEGva6icVIOFs75i7rRPAXjpgdv58r23qNXgJAYMf5IzL74cr7ewK3vnls1kZ2Zw7pW92LllM288/rB9wnFoeVYn+t0/lOvue4SEqtV4f9RTLJv3XZH7Lp33HZdc35/I6GhmTXmP3xf8WPCcAXzlZHa9SCgoeIsE2IEJqL/rfPnCH/nfkp9p1qY9Tdt0IHfPHuZO+4TdO7aTXK8Bi7+bhc/n4+JrbqRrn+sZ+JjNbOfP/LLI9S7p15+ufa6n/YUXA7Dlrw3k7tnDL99/S1h4BPe//Cbn9+jLNXcNoUGzFgXnVYiN49bHnqXvHQ8AsD1tE/l5eXhyc1i9dAmvDR/CW/95lP8tXQzAuj9+K3Lf3rfdQ9c+19Oiw1n77ru+yPNlvZqcSCgpeIsEmOuA2izN2nQA4KtJE9mTlUnTNu05udXphIVH8NG40cBhxrsPU+SlYkJlAMLC7CjY/tn1kcRUjMftdhMWHl5wzOfz8sXE11n24/e0Oqszj7z+Hhf0/D8APLm5h7yvOyx8332Lzqh3l4+aNCIhoTFvkQBzOw77xzF/8E5dtwZ3WBiNW7UhMiqahqecyv9+WQTY8e4adevz+Vuv8dX7E4irlMCyH78HoMOFFx31nlEVKnDa2eex+LtZPHPbTZx50WVs3fQX7S/oRmx8wjG1Ozc7m22pG1k6d85xvV8AB8pNRTmRUFDmLRJgYQek3gnVqpNUtz4A9ZueQlSFCkBhUAebeTc5vS13v/Aa8ZUrM+Hp4az+dQkXX3cTNz78xDHdd/DTL9K1bz82rvkfrw0fwg9ffFyQJR/Jpf1upnm7jqz+9Re++XASbc/7Z0vWDnzfIlJ8HGM0q0QkkNJzPcz5c2eZ3wx0fw7QuW4VEqKO/seCiBw/Zd4iAVYxonwGsIoRGpUTCRQFb5EAc7scYsLdoW5GUMVEuHGr21wkYBS8RYKgcnREqJsQVJWjytf7FQk2BW+RIEiIDsddTmZfux2HxHL2x4pIsCl4iwRB5eiIclNxzGcMidHlc5xfJFgUvEWCID4ynNhyMoErNiKM+EgFb5FAUvAWCZKTEmPKfNUxtwMnJ8aEuhkiZZ6Ct0iQ1IqLBsp49MbZ9z5FJJAUvEWCJMzlUC8++qBa52WFy4F68dFaIiYSBAreIkHUMCGGsjpvzRj7/kQk8BS8RYIoNiKMWnFRZS77djlQKy6q3EzKEwk1BW+RIGtZPZ6wMrbm24V9XyISHAreIkEW4XbRukalMjN1zevN54V7BvHJ1A9D3RSRckPBWyQEasRGUbMMdJ+7HKhXKZaB1/UlJSWFnj17sm3btlA3S6TMU/AWCZFWZaD7PMxxaFk9nl69erF8+XKMMTRv3pzJkyeHumkiZZr28xYJoR17PMzdtBNfKfwtdDlwVq3KVKlQtI755MmTSUlJoXPnzowZM4Zq1aqFqIUiZZcyb5EQqlIhgg7JCaVu/NsBOiQnHBS4AWXhIkGgzFukBEjNzGFh2m5Kwy+jA7RLrkTNY6ikpixcJDCUeYuUADXjojmjZkKJn8DmcuCMWgnHFLhBWbhIoCjzFilBduzxMD91F/nGlKhxcJdjJ6d1qJl4yK7yY6EsXKT4KPMWKUGqVIigS4NqJMdGlZhxcAeoGRtFlwbV/nHgBmXhIsVJmbdICbU5K5fFm3eHLAv3Z9ttalQiKTaqWK+tLFzkxCjzFimhauzLdmvuy8KDNR7ucopm28UduEFZuMiJUuYtUgpkefJZm57NhowcwOANwG+t2wFwqF8pmgaVYoK2ycjkyZOZMmUKkyZNIizsEPccORKio2HgwKC0R6Q0UPAWKUW8PsOmzBxW7comy5OPy3HwnsCvsNtx8BlDbEQYJyfGUCsuNPtx+3w+XK5DdARmZEBkJOzcCTVrBr1dIiWVgrdIKZWxN49dOXnsyvGwM8dDdp4XKOxe3/8X2x+O/WPnMRFuKkdFkBgdQWJ0OPGR4UFr93GJjoZx4+C66wqPGQOlvKysyIlS8BYpI7w+w9+efP7em0e+z+Aztnvd7YDLcQhzOVSMDKdiRFhIsuvjdt998MUXsGKFffzRR3DVVfZzrxfc7tC1TSTEgjOoJSIB53Y5JESFkxBVQrPo47FkCTz/PPz8s308dCiMGQN79kCnTlC7dmjbJxJimm0uIiVP795w//3QujXMmwfvvgtXXw27dkHHjnDg7PScnNC0UyRE1G0uIiXLSy/BsGGQnm4ft2sH3bvDnXdCXBxMmQJTp8KkSXbs++uvITUVevSAihVD2nSRYFHmLSIly+23w8qV9vNBg2zAHjDAfgR4/307A91xbHd6//4QEaHALeWKgreIlDxVq0JuLmzdCg88AP4KbO+9Z5eN3X+/fbx6tZ19/vrrsH174fk+X/DbLBJEmrAmIiWPywVRUbZ73OezWfbmzXbS2g03QPPmdhw8M9POQv/+e5g+Hc49F+rUsef7fPajSBmk4C0iJZs/AI8fD0lJcO21sGkTvPEG9OxpA3nbtja4v/Ya5OXBHXcUZusiZZAmrIlI6bF1K1Svbgu3LFkCjz9uu9jz823mPWAAnH66zchvvhmuv96epyxcyhhl3iJSelSvbj/Gx8OPP9p13wC//QaffWaLuLzyCvzvf7Bhgw3ijgOxsfZ1CuJSRuinWERKn9697dKwcePgjz9g5kzYvdsuMQNo3NhOZuvbFzp3tmPloMAtZYYybxEpnYYNg6wsWLgQPv8c7rrLZuY5ObaIy/vv25nqLVvCjTfaTU4eeijUrRYpFgreIlJ6xcbCeefZOuedOtlj0dE2cF9zDVx+uT328MP2WH4+7L/tqGqkSymlPiQRKf38gRtg7VpYt85OXvP7/HNIS7OBOzvbLi1LSysM3KtXB7e9IidIwVtEypbkZGjWDN56yz7+6iu7Jvypp+DLL+2ktscegzPOgDfftEVfunWDd94JbbtFjoOWiolI2bNiBdxzj63SlpNjC7uccQY895wN7EOGwI4dMHy4nei2fTvMmGHPPbBrXaQE0k+oiJQ9TZvadd9Ll0LdupCQYCux5ebamepga6GvWWPrqM+cWXiuAreUAuo2F5Gyq1UrG7jBdo+7XFC/vn2ckWGrst13H5x0kp3QduWVReuiq2NSSigFbxEpH1q0gGXL7Nj255/bCW1VqkBKig3kjz5qtx/dfy2444SuvSJHoDFvESk/fv/dTlJbvx4WLIAffoBGjeyY+J9/wuzZha8dPBhGjIBKlVTcRUocBW8RKX/eegvS0+Huu2HuXDj/fLvErFYt+/wLL9gJbwduLaryqlJCKHiLSPk2apTtTvcvLdu82U5ymzHDbjG6cqWt5FajBtSsaV9jjLrUJaT0J6SIlG/t28PXX9vu9G+/tVn4v/5lA/eUKXDWWTB2LFx0Ebz0kj1HgVtCTJm3iMjy5TBrFrz3nt0rPC3N7lT24INw6aVw6622W/2OO6B//8Kyq46jrnQJCS1oFBFp3tz+83igbVt7bPJkyMuzgRugYUP48EN7zHEKi7m4XArgEnQK3iIifvfdV/h5UpLd9ATsGLfPB1FR9vMBA6BaNTse/txzUK9eSJor5Zf+VBQROZTWre2a8HHjbKbtdttSqykp8MEHcNtt0KcPXHyxnbEuEkQK3iIih9Khg+0m/+ADePJJe2zOHLsW/M47oUcPaNIEbr8dliw5+Py8vGC2VsoZdZuLiBxOkyZ2Bvqff9rHK1fChRfaXcnOOw8GDoSff4YXX7TPb98Ou3ZB48YQHm6PbdwItWuHpv1SZmm2uYjIsVq0yO5INn481Kljj33+ud3kJDMT7rrLrgX3+eye4R99BIMGwapV9jUixUTd5iIix6pNGzvG3b07/Pvftkpb9+52t7I33rBd6HPmQM+edvLbPffYLF2BW4qZMm8RkeO1cqXdC3zwYDjzTLuczOezk9sAtm6Fli2hSxd4++2QNlXKJo15i4gcryZN7EQ2sGvD//wTHnqo8Pkff4S9e+HxxwuP+UuqGmM3RqleHWJigttuKTPUbS4iciIiIuCMM2DoUFi3Dr75Bm68EZ56ytZI9/MXdvniC5g40c5QV8en/EPqNhcRKQ7PPGNnmr/0EnTrZier+fmz7hkz4LLLoGlTWLq08PkdO+ze4iLHSJm3iEhxuP9+W/v8ssvg2WcLj/sDt8dj136fcYbtLu/Xzz6/cqWt1uZfjiZyDJR5i4gEw9y5MGYMdOxoJ7p9/rmdqd6xI7RqBa+8YoO7f324yBEo8xYRCbSMDJg+3W5ect119lj37ra4y8KF0LkzbNmiwC3HTMFbRCTQXC67/vvOO6FSJXts7Vq4+2645RbYvRtOO83uZCZyDBS8RUQCzRhISIAXXrCT2gCuuspucjJmjN2l7OWXYeZMOza+P58v+O2VEk/BW0Qk0CpWhGnTbD10n88WeMnMLKyJDvDee7Y2ekRE0XP9+4WL7EdFWkREgqV/fxuIZ86EV1+1s9ABPvvMbnDi31p06FCIi7NrwZ9+uuh6cREUvEVEgsvlgnnzCh/n5dmx74cftkH6P/+xBV6WLYMGDeya8ZEj4aKLCs/xLz+TcktLxUREQumxx+xM9Pnz7SS2Tp3gkkvgjz/sePiWLTYjf+yxoucpgJdrGvMWEQmlRx+Fr76yny9YAM2awWuv2V3LbrsNrr4asrLs8198AWPH2s8dB7ze0LRZQk7d5iIioeZfPnbWWfDOO3b/73POsXuCjx8PjRvbTPvaa+1uZXv3wuWXQ/369jxl4eWOMm8RkZKiTh07xt2rly2xmpFhNzk580z4v/+zwfo//7GB+swzYc0ae56y8HJHY94iIiXNypVw331wzTXQp4+djd67N2zcWLiBydVX2wBesaLdN7x27dC2WYJKmbeISEnTpImtfd6nj11adsUVMGpUYeBesMDuWpaTY4u6tGtnJ71JuaExbxGRksoYO9t80CBbRtWvb18YMQIeesg+3rnTZusXXVR07NvrBbc7uG2WoFDmLSJSUjkOJCfb0ql+/fvbLUWHDrWPjYGvv7aT2BwH1q+3s9LBBm5VZyuTNOYtIlJa7N1rS6yOGwfNm9tjI0faMqt//mm7zj/4wH4eF2e3Ga1TJ7RtloBQ5i0iUlpERtrqbP7AvXy5nX3+xhv28Zo1trjLd9/ZLUf797eZuD9HU65WZijzFhEprQYOtNuJTppky6x6vXaW+tln2+Vm69bZEqtgs/bISPu5xsJLPQVvEZHSbs4c+P13W5Ft8WJ44glbH71xY1t29Y8/YNEiW73tttvsOT6frbMupZK+cyIipd1JJ8HHH9tCLiedZLvNly+3gfvBB21mft99dueyq6+22brLZbvRf/451K2Xf0DBW0SktKtZE775xmbW114LF19s14ZPmQKnngq5ubbM6nPPQcOGsG2bPe+rr+yY+X//G9Lmy/HTOm8RkbLikUdgzx4ID7eZ9bZttgrbiy/CkCG29Or27XbGekwMzJoF9erZOuqgsfBSRJm3iEhZUqGCDd4ALVpAWpr9/Kmn7G5lfftC16625OrmzXDrrYVj3wrcpYaCt4hIWdW3L/z4o92BbOVKaNMGnn7ajonPm2ez8pNPhgsuKNyW1E9zmUs0BW8RkbKqdm3bNX7GGfDkk3bpWGqqrcBWubKdvOY40Lq1LeqyP20xWqJpqZiISHmQmWkD9NNPw9KlcPPNdux78WJb0GXpUqhWDX76CX77Da66qnAjFO0XXuIo8xYRKQ/8mXWLFtC+vQ3cYEuq/utfNnB/8QXccYddPuafkQ42cKtGeomizFtEpLzZv0DL6NGwahUkJtrlZtddZ3cwW7vWHv/hBzupTTXSSxRl3iIi5c3+ldVefRXGjLH7gj/xhA3cGRl2rfjPP9u9xS+7zG6GIiWGgreISHk2dSq88IKd0Na5sz12zTWQkwMzZkCjRjB3rs3KU1OLnuv1Br25YqlIi4hIedakif0HNhhv3w4bN9qJbFu22M1PwsLsP3/G/r//2brpbrcKu4SIMm8REbHcbkhKgo4d7Vh3ixY2677kElsz3eOBO++0Y+Bdu9p9wxW4Q0IT1kREpKh337VLygYNspk32ProaWm2Vvq6dTBzJjz8MEyYUNjdLkGj4C0iIgdbuRJSUuCUU+Duu6F6dYiKgsGDbT30e+6BJUtsRn5ggRcJOAVvERE5vPXr7SYm8+bBlVfaeuhPPGF3LbvwwlC37qi8PsPfnjz+3ptPvs/gNQafAZcDbschzOVQMTKMihHhuF2lpxCNgreIiBzZ33/bOulRUXZ2+g03QFYWfPhhwUuMMTgloApbxt48duZ4SM+xH7Pz7Ix4f1zeP+D5W+vbdzAm3E3l6AgSosOpHB1BfGR40Np9vBS8RUTk2Dz5pN0jPDnZFnPp3RuA/Px8fv31V9asWUOvXr2C3qx8n2FTZg6rd2WT5cnH5Th4TyC0uR0HnzHERoRxUmIMteOiS1xWruAtIiLHzr/FaHJykcPTp0+nX79+dO7cmTFjxlCtWrWANyXLk8/a9Gw2ZOQABm8AopnbAXCoFx9Nw4QYYiNKxgprLRUTEZFjl5x8UOAGuPjii1m+fDkAzZs3Z/LkyQFrgsfrY2FaOjPXb2d9xh68JjCBG8BrwGsM6zP2MHP9dn5OS8fjDX2dd2XeIiJSrKZMmcKgQYMCkoVvzspl8ebd5O+beBZsLgfCHIc2NSqRFBsV/Ab42xGyO4uISJnUs2fPYs/C/dn2/NR0PL7QBG6wk9s8PsNPqekhzcKVeYuISMAURxa+Y4+H+am7QpZtH44/C+9QM5EqFSKCe++g3k1ERMqVo2XhO3bsOOL5W7JymbtpZ0iz7cPxZ+FzN+1kS1ZuUO+t4C0iIgFVrVo1pkyZwiuvvEJKSgo9e/Zk27ZtfPfdd1SvXp1vv/32kOelZubwU2p6iQvaB/IZ+Ck1ndTMnKDdU93mIiISNNu2bSMlJYXZs2fj8/lIT0/npJNOYsWKFbj32+RkS1YuP6WmU5oClAOcUTMhKBPZlHmLiEjQ+LPw0047jfT0dAD++usv3njjjYLX2DHu0hW4wVZvm5+Wzo49noDfS5m3iIgE1Y8//siZZ55Z5Fh0dDSbN28mOjaOr9dtw1PS+8qPIMLl0KVBNSLcgcuPlXmLiEhQRUdH0717d5o1a0bFihUByMnJYeDAgSzdmkF+Kc8p841h2daMgN5DmbeIiITUnj17WL58OXHJdViR5St13eWHEujxbwVvEREJOY/XV+q7yw8UyO5zdZuLiEjIlYXu8gMFsvtcwVtEREIqy5NPamZuiV/Pfbx8BjZl5pLlyS/2ayt4i4hISK1Nz8YpWdtlFxvHse+vuCl4i4hIyOT7DBsycspc1u3nM7AhIwdvMb9BBW8REQmZTZk5UCbmlx+J2fc+i4+Ct4iIhMzqXdl4y3js9hpYtat4u84VvEVEJCQy9uYFZDJXSZTlySdjb16xXU/BW0REQmJnjgdXWZ2pdgCX47ArR8FbRERKufScPLxlbG334XiNYVdO8W1YouAtIiIhsbMYg1lpsDNXwVtEREoxr8+QnecNdTOCKtvjLbYlYwreIiJyEMdxcByH3NzcgmMdOnTAcRzmzJkDQL169XAchw0bNhzTNf2vX7lyJX97im/892ieGdyfHk2SmfflZwBsS91EjybJ9GiSzJaNfwKw8Juv6NEkmWcG9w9YO35f8CNhbhedO3c+4WspeIuIyD8yevRoJk2aRNWqVY/73L/35uMK0ly1Zm07ALBi0QL7cfGCguf8x/742X5s1qZ9wNpRnHPzFLxFROSwdu7cyY4dO9ixYwf5+UWXdQ0ePJi+ffuyffv2475u/iG6jx+7sQ/92jend4u63NypNeP/8yher+1aHz3kTno0SeblB+/krsvO55rTT+K9F55izidTuOmslvzrjFOYOfm9Q97LH5D9QXvFogUk1alH9dp1C479sWg+AE1b29fO+OBt7rikE31bNWDQhWcw+eXn8e57/49e14MeTZJ568lh3H7xOVzb+mTGDr2v8Gu2JY0X7x/MzeecTp9T63PHJZ3I2Lmj4Pk9e/bQr18/EhMTady4MQsW2DasXbuW0047jbi4OKKjo4/49VPwFhGRw6pVqxZVq1alatWqLF68uNiu6zXmoLpqJ7dqzbX3PES/B4ZRt3FTpr39Bt9O/aDIa35bMI9u/9cPx3H46LWXmPb2G1w5YDBZGbsZ/++h7M09uJJZvSbNqRBXkb9WrSQ7829WLF5A09btaNamPSsWLSAnO5v1K34nOiaWek2b88MXHzNu+BCMMdz08ONUrl6D/778PFNfe6nIdZfO+45Lru9PZHQ0s6a8x+8LfsTr9fKfW6/n+8+m0qxtB24e9h9antkJn7dwfP/nn38mKSmJK6+8klWrVvHAAw8AEBYWRo8ePRg1ahSPP/74Eb9+Ct4iInJY06dPZ+bMmcycOZOmTZsW23UPTLz35uwhdf0a3nziEd584hF++f5bANb98VuR13XtfT1d+1xPnZObAHDZjbdy6fX9SahWHc/eXHZt3XLQvVwuF01Ob4vP52PhrK/YtHY1zdp0oFmbDqRtWMeCmdPxeb2c3Ko1brebBbO+AqDnwDu5oOc13DBkOADzv55e5Lq9b7uHrn2up0WHswDY8td6Nm9Yx4aVf1A1uRZ3PjeG83v05caHHiOhWvWC85o1a8bTTz/NkCFDAFizZg0Aubm5TJs2jQEDBnDfffdxJGFHfFZERMq1c889l6ioKAAqVqxYbNc9cLz7u88+4scvP6dRi1b0SrmbVcuW8OHYUXj2mzAHEBMfD0BYWDgAsfGV7PVcbgC83kNXbGvWpj1LvvuGj19/GYCmbdrj7BuE/mjc6ILXHMrhxqorJlQGwL2vLV7vsc2e988RCA+35/mHI0aMGMH8+fO54YYb6Nu37xGvocxbRESKxf6zyY/G7TgcKiZ6cnPZtW0rC/dlv8WlWRs7aS113RoqVa1Gjbr1SapTj8TqNUhdZzNf/3h3hwsvAuDDV19k1pT3mPD0Y/Z4l4uPep8a9RpQt3EztqdtYtS9KXw79QPeenLYIXsEDicjI+OoX0MFbxERKRZmX7W0sLCjd+qGHZB6d7q8B+0u6MaWjRv4fMJrtDmvS7G2reEpLYncNwnMH6Tt5+1se8IjOKnlaQCcdckVDBj+FABv/nso29M20SvlbnrccvtR7+N2u3lw7ATOvvRKfl/4I68NH8LSuXNwH8PXZPjw4bRu3Zrp06fz6aefHvG1jjHlpDadiIgETEZGBomJiXTt2pXp06cf9fXpuR7m/LmzzG8Guj8H6Fy3CglR4Sd8LWXeIiJywn744Qeio6MZO3bsMb2+YsSJB7DSqGJE8Uw1U+YtIiIh8fW6bWSVoxKpsRFuutSvVizXUuYtIiIhUTk6ItRNCKrKUcX3fhW8RUQkJBKiw3GXk/283Y5DYjH+saLgLSIiIVE5OgJfORm59RlDYnTxjfMreIuISEjER4YTW0wTuEq62Igw4iMVvEVEpAw4KTEGdxnvOXc7cHJiTLFeU8FbRERCplZcNByy1lpZ4ux7n8VHwVtEREImzOVQLz46aHt7B5vLgXrx0biL+Q0qeIuISEg1TIihrM5bM8a+v+Km4C0iIiEVGxFGrbioMpd9uxyoFRcVkEl5Ct4iIhJyLavHE1bG1nyHOQ4tq8cH5NoK3iIiEnIRbheta1QqM1PXHKBNjUpEuAMTZhW8RUSkRKgRG0XNMtB97u8uT4qNCtw9AnZlERGR49SqDHSfB7K73E/BW0RESowIt4sONRNLbfbtcqBDzcSAdZcX3CegVxcRETlOVSpE0CE5odSNfztAh+QEqlQI/G5pCt4iIlLiJMVG0S659Exgc4B2yZUCOs5d5H7GlNWl8SIiUtptycplflo6vhIcqWxXeQJJMcEJ3KDgLSIiJdyOPR7mp+4i35gSFcRdjp2c1qFmYlC6yven4C0iIiWex+tj6dYMUjNzKQlBy8EuB2tZPT7gk9MOeX8FbxERKS02Z+WyePPukGXh/my7TY3gjW8fioK3iIiUKh6vj2VbM9iUmYvjEJQg7nLsJiOhzLb3p+AtIiKlUpYnn7Xp2WzIyAEM3gBEM7cD4FC/UjQNKsUEZJORf0LBW0REpJTROm8REZFSRsFbRESklFHwFhERKWUUvEVEREoZBW8REZFSRsFbRESklPl/NKr3UoMRqTMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 480x320 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Fetch records\n",
    "records = recall_vector_store.similarity_search(\n",
    "    \"multi-agent\", k=3, filter=lambda doc: doc.metadata[\"user_id\"] == \"3\"\n",
    ")\n",
    "\n",
    "\n",
    "# Plot graph\n",
    "plt.figure(figsize=(6, 4), dpi=80)\n",
    "G = nx.DiGraph()\n",
    "\n",
    "for record in records:\n",
    "    G.add_edge(\n",
    "        record.metadata[\"subject\"],\n",
    "        record.metadata[\"object_\"],\n",
    "        label=record.metadata[\"predicate\"],\n",
    "    )\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    node_size=3000,\n",
    "    node_color=\"lightblue\",\n",
    "    font_size=10,\n",
    "    font_weight=\"bold\",\n",
    "    arrows=True,\n",
    ")\n",
    "edge_labels = nx.get_edge_attributes(G, \"label\")\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa8f770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
